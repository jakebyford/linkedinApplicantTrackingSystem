{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f1ccfa",
   "metadata": {},
   "source": [
    "# LinkedIn Web Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccef1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Dependencies\n",
    "# from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from selenium.webdriver.support.wait import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "# # from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "# Import Dependencies\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from config import my_directory\n",
    "\n",
    "# create webdriver object\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b60a1",
   "metadata": {},
   "source": [
    "## Change ```keywords``` variable to search the job you want. \n",
    "%20 stands for whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269fa159",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Web scrapper for infinite scrolling page #####\n",
    "keywords = 'data%20science'\n",
    "# location = 'New%20Jersey%2C%20United%20States'\n",
    "location = 'Florida%2C%20United%20States'\n",
    "url = f'https://www.linkedin.com/jobs/search?keywords={keywords}&location={location}&geoId=&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0&refresh=true'\n",
    "driver.get(url)\n",
    "# time.sleep(2)  # Allow 2 seconds for the web page to open\n",
    "scroll_pause_time = 2 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
    "screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    # scroll one screen height each time\n",
    "    driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "    i += 1\n",
    "    time.sleep(scroll_pause_time)\n",
    "    # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "    scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "    # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "    if (screen_height) * i > scroll_height:\n",
    "        break \n",
    "\n",
    "##### Extract LinkedIn URLs #####\n",
    "urls = []\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "for link in soup.find_all('div', class_='base-card'):\n",
    "    urls.append(link.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842159b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f68f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/jobs/view/data-analytics-intern-summer-2025-at-miami-heat-4171081062?position=1&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=g1ekcL6Y0JNAkKuLHtIFKg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/ai-ml-engineer-at-disney-experiences-4169946808?position=2&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=XRX9NKoMAW7JD%2BiT2241Qg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-science-intern-summer-fall-2025-at-walt-disney-world-4169944917?position=3&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=GLRD60AkTLQH3KRrMIEZvg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-specialist-at-cgs-4164382346?position=4&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=ofFrboMLdbrzKFMjp5R2Rg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-remote-at-synergisticit-4045409698?position=5&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=pb1ZZDSVb4r5RIPYjjAOpA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-analyst-remote-at-synergisticit-4045413346?position=6&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=U9mvtqfTn50OFOUuTnmmXQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-analyst-remote-at-synergisticit-4045413395?position=7&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=lNvZB6XtjF8LuGi4N%2BDing%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-at-novisync-inc-4172076016?position=8&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=EfWX8tvzdas%2BwExzrgf%2F6w%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-analyst-remote-at-synergisticit-4074784025?position=9&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=9jBpraFncyBBYRYo%2FUYSxw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-scientist-remote-at-synergisticit-4045407938?position=10&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=Nfa0OtnPqEoWB7dPmjyTUw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-at-spot-pet-insurance-4153870888?position=11&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=hCI8%2F15GzXfZXyZv9NyVDA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/spring-data-analyst-intern-at-sitezeus-4138744657?position=12&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=Y8x24TQMcfY4GwcKeBXh8Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-remote-at-synergisticit-4045410586?position=13&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=X%2FeXyvYihYWU%2FVA50tngPg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-at-doodie-calls-4154797167?position=14&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=Unvj9HMER5MhWQNQ3k6S4g%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-specialist-at-cgs-4164380432?position=15&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=wHgyv9ABCJXdl%2B47%2BVHN4w%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-entry-clerk-at-messa-sync-4161984883?position=16&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=2UH2qd%2FsXcClcM0QoMu8MA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-verizon-4172081878?position=17&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=3m%2F4DgzDa3FN7YSkE6NMrw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-at-hayes-locums-4174487349?position=18&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=%2B6ORm722mW10zP9r7q6t1Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-scientist-remote-at-synergisticit-4112268268?position=19&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=4JSf9wnzgFTu4IMe9k9xqg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-junior-level-data-scientist-python-programmer-at-synergisticit-4045409761?position=20&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=SCll5Btgwni3C9SP3z9HFA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-machine-learning-engineer-at-synergisticit-4149068800?position=21&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=WKMpSZFFwWWFagbOcHs5MA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-gerdau-north-america-4143571714?position=22&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=O74xF%2BNCur0dTugOX0gwTw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-remote-at-synergisticit-4045407964?position=23&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=VKj7NvcVWXJa2kJ1EYZ73A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-analyst-remote-at-synergisticit-4045413935?position=24&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=TA9gKkXR%2Fh1T1ZKVyMJw1w%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/machine-learning-engineer-i-at-lennar-4090179627?position=25&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=pk%2FS1fxJOO%2FykYm98YxBAA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045410497?position=26&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=hC6E8QSoiypzWJLF%2F%2FOn0Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/associate-data-scientist-at-reliaquest-4139278095?position=27&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=q3rxNkx5Nq38mLUP06yUpg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4171657011?position=28&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=XI1czY3EBvyCEoG4AkqDOw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/health-data-analyst-64007035-at-state-of-florida-4172351191?position=29&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=dxy6vD7bxPdvO3peL2WP5Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-surecost-4152258208?position=30&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=iYj60lSGKe%2FGBscJBHe2KA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-junior-level-data-scientist-python-programmer-remote-at-synergisticit-4045408848?position=31&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=hU%2FIFOQqN%2FSy%2FF8IQBV5rw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045412338?position=32&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=sucM7hddZzOhNytyTZi2UQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analytics-intern-summer-2025-at-tietalent-4174622467?position=33&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=BrW2ihlJu45Pj2uN%2BWTegw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/business-data-analyst-at-dexian-4165746781?position=34&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=U9wAGxfA1Uc4bXCdai4Daw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-at-reliaquest-4170550489?position=35&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=osoI%2FBC0T%2BOMVAWMYxVXxA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-junior-level-data-scientist-at-synergisticit-4045412461?position=36&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=TRL41%2BFXf8%2F3zzYgcJxZ2A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-hut-8-4090007531?position=37&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=qmljC9fuVj5LqLOcBUOBOQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045409580?position=38&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=pLctCHH9q3i7XFy9hQ9Svw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-onerail-4126256511?position=39&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=o6EWtXq5yHwa8j6HXKVZBA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/business-intelligence-analyst-applied-ai-at-surecost-4172392566?position=40&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=ES4wafD3p%2FRFLyYV9%2BIC9g%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170608554?position=41&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=yGC9cF%2FsoRVmKjdyiNxmyw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-machine-learning-engineer-at-synergisticit-4070299251?position=42&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=h3yWf%2FAzrdUMkjnk7yiqLA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-remote-at-imarketresearch-4103449612?position=43&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=Zf%2F%2Foj8TzLe%2FkmAGaflanw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-junior-level-data-scientist-python-programmer-remote-at-synergisticit-4045409783?position=44&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=gPAwwtR2YZWGWLF0QrK6Zw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/remote-data-scientist-analyst-entry-junior-level-at-synergisticit-4045409883?position=45&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=W8KuUwObPkZHo5y6CnGd0A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045410493?position=46&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=f7rRYZnHasIQt2XuiofwJQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-machine-learning-engineer-at-synergisticit-4045411436?position=47&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=FFx9tuyI3FXWXKUmYx0sYw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045407805?position=48&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=ZkHHhrsQAI%2BFej6PF9JT4A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170610987?position=49&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=jweqq7S5hlaEnWXkfhLeTg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-ml-engineer-at-synergisticit-4106452358?position=50&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=GNFcqbT2WWOP43YgWBY9EQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-southern-glazer-s-wine-spirits-4171055321?position=51&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=59Xh9Hhfo6motIOH8%2Bk7vg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045407865?position=52&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=zx6SgQipk8srQSTM66t4dw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170612621?position=53&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=v7CP4ndKqvBSalFiMaSmog%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/sales-development-representative-orlando-at-resulticks-4167235563?position=54&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=Zs9JLSFRwI5zPWGASueyQw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-intern-2025-at-voloridge-investment-management-llc-4136626361?position=55&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=88XleTS57keVYlnrulqIMQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/intern-research-and-development-at-tampa-bay-rays-4082644299?position=56&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=RL%2Bl6sTUQ%2B9gUj8DuWapRg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analytics-intern-at-u-s-hunger-4145538711?position=57&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=0F02vJ8FjQxpz4bC2OUFgg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045412289?position=58&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=udT9gOH6UJl1JUTa4b%2Fe8A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/leadgen-data-scientist-at-symple-lending-4076058289?position=59&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=nqw2OiCUARo0MCx21nSlJA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/python-developer-at-amerilife-4139329227?position=60&pageNum=0&refId=GT2d2ohNYn4beIMYp8ECpw%3D%3D&trackingId=DphKSvqV9EhT9WfCfw4kzQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045410497?position=1&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=rNc%2FAHSlbcX%2FIfqYZrKcmw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/associate-data-scientist-at-reliaquest-4139278095?position=2&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=hpdwy0jhHoWvwwrUKRTzsA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4171657011?position=3&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=je4Lwxi79oqKULvd95cTzw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/health-data-analyst-64007035-at-state-of-florida-4172351191?position=4&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=gXjhM4XeyuqUWmx4FyPKdw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-surecost-4152258208?position=5&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=WUXyDu%2FW5KhIccKasne9iA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-junior-level-data-scientist-python-programmer-remote-at-synergisticit-4045408848?position=6&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=g691egeMtssprHcKfC5S0A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045412338?position=7&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=kJaLwRbS%2F8R3ovfQv%2FtSAA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analytics-intern-summer-2025-at-tietalent-4174622467?position=8&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=1zzZX9kDGfRw0Q9XR1d8dA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/business-data-analyst-at-dexian-4165746781?position=9&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=r2ts2JeyNszDUmmiC5Ni3Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-at-reliaquest-4170550489?position=10&pageNum=2&refId=FExs78kWUvIGGfgVap7I7A%3D%3D&trackingId=cTKGZT5l2uUeZNxIQp5B6w%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-southern-glazer-s-wine-spirits-4171055321?position=1&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=n4pXQO%2BUz9NP2htfnfZC3A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045407865?position=2&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=w9dy6AFYsblXBWvfXznU2w%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170612621?position=3&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=GIH9UQ14LlQXI7uzuixOLA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/sales-development-representative-orlando-at-resulticks-4167235563?position=4&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=s%2FeIsAOl2E25gdM11Fipjg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-intern-2025-at-voloridge-investment-management-llc-4136626361?position=5&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=4pfcX%2B%2BEa2XbAVw5goK5Tw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/intern-research-and-development-at-tampa-bay-rays-4082644299?position=6&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=n9PzuaXI3jHDCux2iWbtrA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analytics-intern-at-u-s-hunger-4145538711?position=7&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=oXoqOOAORSVREOZZcmllIA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-at-synergisticit-4045412289?position=8&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=N%2B0qKmGTY2wjdObmBwS4mA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/leadgen-data-scientist-at-symple-lending-4076058289?position=9&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=PSCx%2FgbvVlUxesPTfbak6g%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/python-developer-at-amerilife-4139329227?position=10&pageNum=5&refId=rew%2FmcFXyJq4ts8jzbB4UA%3D%3D&trackingId=LlN1xVySc8RfQYLYsR4h5Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-scientist-engineer-remote-at-synergisticit-4045411892?position=1&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=jY7PoZUp8IC5%2BZUnCTU%2Frg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-python-developer-at-synergisticit-4045426570?position=2&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=%2BpgLJAB%2F6bJNlGc3u1Q7fQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-python-developer-at-synergisticit-4168495138?position=3&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=MdplRmejxZq%2FxX5Etls%2FvA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-scientist-analyst-at-synergisticit-4045410886?position=4&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=HL%2FyPMzeqb0GkAxT1ck14w%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/quality-assurance-analyst-at-maverc-technologies-4153468498?position=5&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=xkUHsztyAi3rN1N3LLISzA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/remote-data-scientist-analyst-entry-junior-level-at-synergisticit-4045408794?position=6&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=PJCP9S4p8no7QZHShhaaTA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/remote-data-scientist-analyst-entry-junior-level-at-synergisticit-4045412519?position=7&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=PmsCjCmlee7zf6I%2FlD5j3g%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/machine-learning-engineer-at-design-interactive-inc-4151865965?position=8&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=13JPJbvzBQlNoyATdwCUGg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-level-python-developer-at-synergisticit-4045409642?position=9&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=QOboNXwQT79uo%2FQ%2B8kHtwQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-analyst-at-synergisticit-4045408643?position=10&pageNum=7&refId=QIzM%2FOgQ39Jh%2BquM8VGGLw%3D%3D&trackingId=Mv6rxEijS5dZD3FtjKsVug%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-entry-technician-at-cgs-federal-contact-government-services-4115092724?position=1&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=ohX9ojkFhi53oeO0zgASCw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-machine-learning-engineer-at-synergisticit-4097614204?position=2&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=Pw9xj2yvlG75eykJJlKCYA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-scientist-engineer-remote-at-synergisticit-4045410948?position=3&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=bHPAk%2Bk4jIXdZeFrsUrxWw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170636412?position=4&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=%2BMlhbJgrA%2FXCulc8QzIDwQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-ony-on-w2-at-chelsoft-solutions-co-4126015127?position=5&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=xiIWofYjNCS9dX%2BUzwGoWQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-slalom-4053940166?position=6&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=aZIvzYTVijfjaomYgaBtaQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-engineer-remote-at-tietalent-4167881095?position=7&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=DoNJBQWTeB20mqmdKsejkw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170609998?position=8&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=nQ6%2FGpDnmZCRnH5MP%2BQGjw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/business-analyst-at-maverc-technologies-4140315655?position=9&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=Em240Mw5FWua%2BGlDGKD43Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-analyst-at-synergisticit-4045413760?position=10&pageNum=10&refId=L18emGipDljBlu%2FcIKfX1Q%3D%3D&trackingId=2UTjdmXHf8wUxg2%2FRu2M5g%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-bi-analyst-at-seneca-resources-4174481528?position=1&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=cpnx%2BLtg4Z3CSmgl%2FOxs1Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/contact-center-reporting-data-analyst-at-mount-sinai-medical-center-of-florida-4133632722?position=2&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=1Sy0CTmRPwD3huJizWxLvA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-scientist-engineer-analyst-remote-at-synergisticit-4045414333?position=3&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=3jdDUj%2FMiXTeKrpqFNxUIA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170645069?position=4&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=ny852TvzWdLoZ0ix%2FzGSng%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-analyst-scientist-at-synergisticit-4045411622?position=5&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=fJEG0tS0u70fW72wPn6Pdg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-entry-technician-at-cgs-federal-contact-government-services-4115085766?position=6&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=hAvlj4%2BpwANsdF%2FkSTMqsg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-outlier-4170639883?position=7&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=YlgVM%2BPqWBU0vaxJkVJGnQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-entry-technician-at-cgs-federal-contact-government-services-4115201362?position=8&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=buVSRcpoob9OQSP1F3ueNQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-entry-technician-at-cgs-federal-contact-government-services-4115098531?position=9&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=5OBoNyNXAEdVM2Ez1D6ZZA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/healthcare-economics-analyst-i-at-capital-health-plan-4103462841?position=10&pageNum=12&refId=heOpW58Zk4XU34GrPzaFyA%3D%3D&trackingId=DuYitibXHkAQH8gtIJZX4Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/entry-level-data-analyst-at-synergisticit-4114547910?position=1&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=66Tl2YuZRKVbty742me4pg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-data-scientist-entry-level-ai-software-programmer-remote-at-synergisticit-4105543913?position=2&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=P%2BScZnnGuObWBZiGa8ZyIw%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/systems-analyst-data-analytics-at-cgs-4164511871?position=3&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=RZHZ9tvv9dEpMJN4PlegXA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/junior-business-analyst-remote-at-synergisticit-4076945853?position=4&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=eydpGIIq6ci338IRFZuH3Q%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-remote-at-synergisticit-4045412857?position=5&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=I8%2Bm9cTFhiFnG3BXB5jiJA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/remote-entry-level-python-programmer-data-scientist-analyst-at-synergisticit-4045412516?position=6&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=0EnLQh6hzYfSBfj1musXhg%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/senior-director-of-analytics-at-10x-health-system-4168619673?position=7&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=qEoaGpo2pgbdnMklh%2FBR%2FQ%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/engineer-1-data-science-at-verizon-4171227790?position=8&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=NV%2BTIO3odyp66kyGCpHy9A%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-engineer-at-cgs-4164383212?position=9&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=jCg4BOQ9m%2BFWNilAeJjDbA%3D%3D',\n",
       " 'https://www.linkedin.com/jobs/view/data-analyst-remote-at-synergisticit-4045410618?position=10&pageNum=15&refId=R0yLAzmNfCTSOzLDGtG0CQ%3D%3D&trackingId=CBElU%2BOlDmAgIgf%2Fnp1ZNQ%3D%3D']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db03a7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are any duplicates\n",
    "len(urls) != len(set(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060bdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    if (i.__contains__(\"meta\")):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3f612",
   "metadata": {},
   "source": [
    "## Directly change ```my_directory``` variable or create a config.py file to import ```my_directory```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe542a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_directory = \"C:/<example_Desktop>/<example_directory>\"\n",
    "\n",
    "os.chdir(my_directory)\n",
    "\n",
    "SCRAPED_JOBS_PATH = my_directory + \"/temp_data_science_job_descriptions\"\n",
    "\n",
    "SCRAPED_JOBS_PATH_EXIST = os.path.exists(SCRAPED_JOBS_PATH)\n",
    "\n",
    "if SCRAPED_JOBS_PATH_EXIST == True:\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(SCRAPED_JOBS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e4e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(urls[0])\n",
    "# #     time.sleep(2)\n",
    "# soup = BeautifulSoup(page.text, 'lxml')\n",
    "# div = soup.find_all('div', class_='top-card-layout__entity-info')\n",
    "# section = soup.find_all('section', class_='show-more-less-html')\n",
    "# section_divs = [i for i in section]\n",
    "# job_desc_sentences = [i.text for i in section_divs[0].find_all('li')]\n",
    "# job_desc_sentences = ' '.join(job_desc_sentences)\n",
    "# job_desc_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c2c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# div[0].h4.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9beebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position_title = div.h1.text\n",
    "# company = (div.h4.div.span.a.text).lstrip().rstrip()\n",
    "\n",
    "# file_name = f\"{position_title.lower().replace(' ', '_')}-{company.lower().replace(' ', '_')}.txt\"\n",
    "# file_name = file_name.replace('(', \"_\") if file_name.__contains__(\"(\") else file_name\n",
    "# file_name = file_name.replace(')', \"_\") if file_name.__contains__(\")\") else file_name\n",
    "# file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e062e8-5355-461a-8e68-c09705188a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eebfe3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development and evaluation of predictive and generative machine learning algorithms to analyze molecular datasets for drug discovery.  Collaborate closely with other machine learning scientists, computational biologists and chemists to develop and execute the research project.  Document and disseminate research findings internally and externally (e.g.- publishing in top-tier ML conferences/journals). Currently pursuing PhD degree in Data Science, Computer Science, Electrical Engineering, Statistics, or related quantitative discipline. Exceptional Master’s degree candidates are also encouraged to apply. Strong working knowledge of machine learning with demonstrated research experience, as evidenced by publications, public code contributions, etc.  Proficiency in Python and hands-on experience with Deep Learning frameworks such as PyTorch or TensorFlow to solve scientific problems.  Strong technical communication and presentation skills.  Ability to understand and write academic research papers.  Extensive research experience working with sequence models (e.g.- with Large Language Models (LLMs)) and/or Graph Neural Networks (GNNs).  Familiarity with Equivariant Geometric Deep Learning and/or state space sequence modelling is a plus.  Knowledge and interest in drug discovery and experience working with drug discovery datasets, including graph, sequence, and/or structure-based data is a plus. \n",
      " Proven experience as a AI/ML Engineer or similar role  Strong proficiency in programming languages such as Python or R  Solid understanding of statistics and mathematical concepts relevant to data science  Experience with data visualization and reporting tools  Knowledge of machine learning algorithms and techniques  Familiarity with data manipulation and analysis using SQL  Strong problem-solving and analytical skills  Excellent communication and presentation skills  Ability to work in a fast-paced and collaborative environment  Master's or Ph.D. degree in Data Science, Computer Science, Statistics, or a related field  Experience with deep learning frameworks, such as TensorFlow or PyTorch  Knowledge of big data processing technologies (e.g., Hadoop, Spark)  Familiarity with cloud-based data platforms (e.g., AWS, Azure, Google Cloud Platform)  Experience with data engineering and data preprocessing techniques  Publications or contributions to the data science community (e.g., research papers, open-source projects)\n",
      "IT experience of 10+ years with minimum of 6 years of experience in data science, specifically in developing predictive models using Data Science, AI/ Client, Python, TensorFlow Proven experience utilizing AWS services in a data science or analytics capacity. Proficient in data manipulation and analysis using libraries such as Pandas, NumPy, and Scikit-learn. Expertise in machine learning algorithms, statistical analysis, and predictive modeling.\n",
      "3+ years of experience with predictive analytics using large data sets.  Strong programming skills in Python are essential, as BI Python Developers use Python for data analysis, scripting and building data pipelines. Ability to analyze and interpret complex data sets, turning raw data into meaningful insights.  Familiarity with data manipulation libraries like Pandas is often necessary.  Proficiency in SQL, data querying, and performance optimization techniques Proficiency in procedural languages such as MSSQL TSQL, Postgres pl/sql Experience with BI tools like Tableau, Power BI. Understanding how to visualize data and create dashboards for business users is crucial.\n",
      "Analyze healthcare data, run descriptive statistics, generate prior distributions, explore relationships: Correlation, covariance, causality, structural equation modeling, and build Bayesian Influence diagrams. Develop predictive models with Deep Learning networks, Gradient Boosting, Random Forest, SVM, LDA, decision tree, and logistic regression using both generative and discriminative algorithms. Sub-group analysis: clustering, agglomerative clustering, graph-based clustering, and PCA analysis. Define and develop features, selections (Ridge/Lasso), and ranking. Standardize nominal, categorical, and numerical data to ensure data integrity. Develop algorithms in order to achieve the desired health outcomes, and improved health behavior in Big data environment SPARK and SCALA. Partner with scientists and business leaders to collect and organize healthcare data, and generate insights for thought leadership. Work with project leaders to roll out algorithms and build dashboards to visualize near real-time insights for targeted audience including scientists and commercial partners. Ph.D. with a minimum of three years of relevant experience within industry is required. A focus in behavior change, social psychology, other public health-related fields, or equivalent focus in biomedical informatics as applied to health behavior is preferred. Experience in the analysis of behavior science and/or population-based interventions to support healthcare and health outcomes is required. Experience in developing and deploying technology-based behavior change solutions is preferred. A passion for excellence and exceeding customer expectations is required. Excellent internal and external customer facing skills are required. Active listening skills, strong business acumen, and strong organizational skills are required. Excellent oral and interpersonal communication skills are required. An understanding of and ability to apply research and program evaluation methodology is required. Experience working with cross-functional project teams is required. Professional scholarly activity (e.g. conference presentations, peer-reviewed publications) is required. An understanding of and ability to apply data science methodologies is required. Experience with ontologies is preferred.\n",
      "Create an inventory of data sources available through the Department Health by surveying and interviewing division and/or program-level data stewards and categorizing data sources by file type. Follow-up with data stewards as necessary to ensure the completeness of the DOH Data Source Overview forms, which provide a high-level description of the type of information in each data source and the potential uses and limitations of the data. Identify race and ethnicity gaps in DH data sources in relation to best practice guidelines/frameworks For priority DH data sources, collaborate with multiple functional areas to 1) assess the availability and granularity of race and ethnicity classifications, 2) document the barriers to the collection of complete and consistent race and ethnicity data, and 3) record the legal and/or policy solutions that are needed to overcome these barriers. The primary responsibilities of this position are to create an inventory of data sources at DH; document the various ways that race and ethnicity are collected within the Department; record the perceived and actual barriers to collecting the required minimum race and ethnicity categories; and log the action steps needed for improved and consistent race and ethnicity data collection. Experience creating a data inventory, data catalog, and/or metadata, or using data to reduce health disparities and improve health equity Strong analytical and problem-solving skills with a critical eye for detail Excellent written and verbal communication skills with the ability to consult/communicate with agency data stewards, agency program staff that leverage and disseminate the data, and community consumers of the data Demonstrated awareness and understanding of New Jersey communities that experience health disparities and barriers to care. Experience and/ or interest in public health or epidemiology is preferred Strong quantitative data analysis skills and understanding of different types of databases. Knowledge of best practices and guidelines for improving data collection and reporting of race and ethnicity to advance health equity Exceptional interpersonal skills with strengths in both written and verbal communication; ability to multi-task, organize, prioritize, and meet deadlines Proficiency in MS Office Suite (Word, PowerPoint, and Excel) A thorough understanding, sensitivity, and appreciation for equity, cultural humility, and inclusiveness. 8:30 am to 4:30 pm Lunch period: 1 hour (unpaid) Work from Office or Remote: Office\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 to 7 years of work experience in the space of data analytics. Should be able to work independently with client business and analytics stakeholders Experience in working with Pharma data sets Strong experience on Python, SQL and/or visualization tools such as PowerBI, or Qlik Ability to understand client’s business problems, working as part of a global team and perform project related studies and analysis Strong experience in implementing commercial data solutions for life sciences companies Attention to details, hands-on deep dive analysis, and strong communication skills Fluency with pharma data sources such as Plantrak, LAAD, PE, etc including RWD sources such as TriNetX, Flatiron, Optum, Komodo etc Good understanding of commercial pharma processes  Adhere to Analytics Lifecycle and best practices A strong aptitude for story telling through the analysis of data Hands-on analytical experience with a proven track record of results Demonstrated ability to translate strategy into action; excellent analytical skills and an ability to communicate complex issues in a simple way and to orchestrate plans to resolve issues & mitigate risks Bachelor's or higher in data analytics or equivalent work experience Preferred experience with cloud platforms, such as AWS or Azure Manage master data, including creation, updates, and deletion Create documentation of analytics use cases Commissioning and decommissioning of data sets Helping develop reports and analysis Manage and design the reporting environment, including data sources, security, and metadata Generating reports from single or multiple systems Troubleshooting the reporting database environment and reports Evaluating changes and updates to source production systems Training end-users on new reports and dashboards Providing technical expertise in data storage structures, data mining, and data cleansing\n",
      "Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions Creating Scalable Machine Learning systems that are highly performant Building reusable production data pipelines for implemented machine learning models Writing production-quality code and libraries that can be packaged as containers, installed and deployed Bachelor's degree or higher in computer science or related, with 5+ years of work experience Ability to collaborate with Data Engineers and Data Scientists to build data and model pipelines and help run machine learning tests and experiments Ability to manage the infrastructure and data pipelines needed to bring ML solutions to production End-to-end understanding of applications being created Ability to maintain scalable machine learning solutions in production Ability to abstract the complexity of production for machine learning using containers Ability to troubleshoot production machine learning model issues, including recommendations for to retrain and revalidate Experience with Big Data Projects using multiple types of structured and unstructured data Ability to work with a global team, playing a key role in communicating problem context to the remote teams Excellent communication and teamwork skills Python, Spark, Hadoop, and Docker with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design Knowledge of ML frameworks like Scikitlearn, Tensorflow, and Keras Knowledge of MLflow, Airflow, and Kubernetes Experience with Cloud environments and knowledge of offerings such as AWS SageMaker Proficiency in statistical tools, relational databases, and expertise in programming languages (Python/SQL)\n",
      "Graduate degree in a relevant field (Computer Science, Mathematics, Electrical Engineering) 2+ years experience in building and deploying ML models Experience in applying transformer-based deep-learning techniques to challenging NLP problems Fluency in Python and experience with Python-based ML frameworks such as PyTorch Outstanding communication skills Publications in top-tier NLP conferences Background in classical computational linguistics Experience with Java (or Kotlin/Scala) and/or a functional programming language Design, build, evaluate, and deploy algorithms and models for accurately extracting medical information from structured and unstructured data sources Work closely with product, UX, and clinical teams to prototype and test new functionality Analyze performance results and convey your analyses to relevant stakeholders Conduct research, publish and present your findings at relevant scientific venues  We lead with empathy for patients and our teammates  We value small egos, self-awareness, and humility in our teammates  We appreciate flexible and adaptive attitudes towards solving problems, as strategic priorities may shift  We love diversity of thought, perspective, working style, skill set, knowledge, and interests amongst our team  We value open dialogue and brainstorming across multidisciplinary teams\n",
      "Lead testing and measurement efforts for our key online marketing channels, especially paid searches, such as Google and Bing. Develop cross-channel measurement models such as MediaMixModeling to optimize budget allocation.  Collaborate with Engineering and Marketing teams to drive LTV bidding optimizations and their impact measurement for our digital marketing channels. Measure the effectiveness of Individual Marketing channels and Cross-Channels by building/leveraging different attribution models and experimentation methods. Devise a solution to inform marketing strategy and drive measurement in a cookieless world. Analyze the impact of our overall marketing budget to understand its full-funnel impact and how it influences Grammarly for Business conversions. Run elasticity analysis to drive discussions and identify opportunities for spending re-allocation across countries. Conduct deep-dive analyses into marketing channel performance and user behavior. Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable. Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust. Is able to collaborate in person 3 weeks per quarter, traveling if necessary to the hub where the team is based. Has 8+ years of relevant work experience. Has experience as an influential and effective thought partner to marketing teams.  Demonstrates strong communication, proactiveness, creativity, and prioritization skills. Has strong analytical and critical thinking skills and a strong bias toward actionable insights. Has the ability to work in a fast-paced, dynamic environment. Has practical experience in data analysis, statistics, and marketing measurement. Is proficient in SQL, Python, R, Scala, or an equivalent language. Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We also support professional development and advancement with training, coaching, and regular feedback. A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities including BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits) Disability and life insurance options 401(k) and RRSP matching  Paid parental leave Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days  Home office stipends Caregiver and pet care stipends Wellness stipends Admission discounts Learning and development opportunities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently pursuing PhD degree in Neuroscience, Statistics, Biostatistics, Data Science, Computer Science, Electrical Engineering, Computational Biology, Biomedical Informatics, Mathematics or related quantitative discipline. Strong working knowledge of data mining and machine learning. Proficiency in one or more of the following programming languages: Python, R, Matlab, Bash Scripting. Familiarity with predictive modeling and analysis of large datasets. Strong technical communication and presentation skills. Experience working with neuroimaging data analysis such as MRI, CT, PET.\n",
      "Work on the entire data production chain by implementing data ingestion pipelines (from multiple sources and in different formats), storage, transformation ... then their provision: datamarts, reports, datasets to feed models scoring (data science), API, ... mainly using Dataiku and Google Big query Ensure that the integration pipelines are designed in a manner consistent with the overall data framework in collaboration with the data tech lead and according to best practices.  Be part of a continuous improvement approach by optimizing and reusing existing assets.  Take part in data integration processing aspects of data quality controls, monitoring, alerting and technical documentation, as well as data management (data models and mapping, data documentation, repositories, description of the transformations applied, etc.) Acquire a good understanding and analysis of business challenges and be able to translate the needs into the design of concrete technical solutions and gradually extend the functionalities and scope of our data platform based on Google cloud platform and Dataiku.  Provide reliable estimates of workloads and planning according to the level of complexity and other activities to allow a good coordination of the activities of the team.  Perform unit development tests and support business users in their tests before final validation.  Contribute to the design and management of the data model, as well as to the orientations in terms of the architecture of our data platform (repositories, APIs, etc.) Set up pipeline monitoring and monitoring of the data platform and APIs (from a functional point of view and data quality) Analyze incidents, points of weakness and support requests related to the use of the data platform or APIs Provide timely and accurate support to the business teams on issues Propose improvements to optimize the data platform (optimization of existing processes, data restructuring, factorization, etc.) Mastery of the data stack components in Google Cloud Platform (certifications appreciated) including but not limited to: Google Big Query (nested fields, partitioning, merge SQL, authorized views, RLS, …), Cloud storage, Cloud functions, Cloud composer, Google Firestore, Google data catalog.  Proficiency of Dataiku (on Google big query): development of dataiku flows, implementation of scenarios, scheduling, management of versioning, releases into production, administration etc.  Mastery of complex SQL queries Good knowledge of Python is a plus Development practices with data exchange architectures: webservice, API, streaming. Salesforce MuleSoft a plus.  Development in an agile team and the tools used in CI / CD (Azure devops, Jira, Confluence) Knowledge of Microsoft Power BI, data catalog tool, data quality, data management Knowledge of Terraform and the administration of Google Cloud Platform appreciated (rights management, API activation, network settings, etc.) Autonomous and proactive Perseverance Curious and a desire to learn Rigorous, organized and attentive to detail Team spirit and knows how to work collectively in multidisciplinary teams Problem solver Very good communication, in particular the capacity of synthesis and popularization to make oneself understood simply Solution designer, knows how to argue and make recommendations when several technical options are possible Proactive team player Bachelor’s degree in Management, Computer Science or related field Bi-lingual English, French is a plus Minimum of 5 years’ experience in IT development roles such as data integration on Google Cloud & Dataiku Experience with Power BI, Tableau or Power Query is a plus\n",
      "Research and evaluate the performance of state-of-the-art computer vision and natural language processing with respect to latest deep learning algorithms. Apply software engineering skills to prototype algorithms to identify challenges for our research. Learn, collaborate, and network alongside world-class researchers and creators to investigate algorithms; present your findings and contribute to industry leading entertainment technology community. Ph.D. candidate, or Post-doc in Computer Science, Electrical Engineering, or a related field. Research background in the area of AI/Machine Learning, Computer Vision, Natural Language Processing or related areas. Strong familiarity with neural network modeling and analysis, formulate optimization flow using PyTorch, TensorFlow or equivalent deep learning framework. Strong familiarity with Python and/or modern C++ for rapid algorithm prototyping. Strong familiarity with camera geometry and geometric algebra Excellent analytical and mathematical skills. Knowledge and experiences in generative models Knowledge and experiences in transformer models Knowledge and experiences in large language models and fine tuning Knowledge and experiences in vision & language multimodal models\n",
      "Acts as the analytic lead for complex clinical analytics projects involving multiple data resources and teams to inform business decisions in clinical, network, value-based payment models, and employer engagement.  Understands the strategic direction of the organization and the analytic and reporting requirements to meet departmental needs. Translates business questions and needs into analytics technical requirements including data analytics design, clinical and data specifications, and reporting format.  Leads the design and extraction of data from multiple sources. Creates integrated analytic datasets. Performs analytics and summarizes findings to inform business opportunities and address business questions.  SHIFT: Monday – Friday, 8 a.m. – 5 p.m. | There is flexibility here if they need to start their days a little earlier or later  High School Diploma/GED required  7+ years of experience in Data Analytics, Informatics, Medical Economics, or other relevant work experience  7+ years of experience performing analysis on large healthcare administrative claims data, EHR/EMR data, or complex relational health care databases with significant experience analyzing medical, pharmacy, and behavioral health claims data  7+ years of hands-on programming experience using SAS  Bachelor’s or master’s degree in Math, Statistics, Data Science, Economics, Epidemiology, Public Health, or related field  Prefers knowledge and working experience of visualization and BI tools (e.g., Tableau, Power BI.) with preference given to Tableau experience.  Prefers hands-on experience of clinical episode groupers and analytics, preferably with Optum’s Symmetry Suite of Services (Impact Intelligence, ImpactPro, ETG, ERG, PEG, EBM, PRG, etc.) or PROMETHEUS.  Prefers knowledge and direct experience of Milliman’s analytics tools such as MedInsight Health Cost Guidelines  Medical, dental and vision plans  401K with 3% company match (fully vested after 3 years)  Horizon BCBSNJ will also contribute an additional 4% into an employee’s Savings and Investment Plan as “Horizon BCBSNJ Retirement Contributions” (HRCs)  Tuition Reimbursement  19 Days of PTO (Starting Jan. 1st) | PTO is pro-rated depending on when they start in the year  11 paid holidays \n",
      "Hybrid, must be onsite 3 days a week. 8 hours a day, may work earlier in the day or later in the day based on working with EMEA. 1 year contract, might be able to extend, but not promised. Must have 3 years exp. Predicting health behaviors and suggesting behaviors to the world (for example suggesting lung screenings) Data Analytics (predictive modeling) Using multiple/big datasets to generate business (ex - SCALA & SPARK) Evidence of translating data analytics within applied healthcare setting Analyze healthcare data, run descriptive statistics, generate prior distributions, explore relationships: Correlation, covariance, causality, structural equation modeling, and build Bayesian Influence diagrams. Develop predictive models with Deep Learning networks, Gradient Boosting, Random Forest, SVM, LDA, decision tree, and logistic regression using both generative and discriminative algorithms. Sub-group analysis: clustering, agglomerative clustering, graph-based clustering, and PCA analysis. Define and develop features, selections (Ridge/Lasso), and ranking. Standardize nominal, categorical, and numerical data to ensure data integrity. Develop algorithms in order to achieve the desired health outcomes, and improved health behavior in Big data environment SPARK and SCALA. Partner with scientists and business leaders to collect and organize healthcare data, and generate insights for thought leadership. Work with project leaders to roll out algorithms and build dashboards to visualize near real-time insights for targeted audience including scientists and commercial partners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking for a Data Science temp who is passionate about data and analysis tools, has the rigor needed to solve problems, and demonstrates curiosity and enthusiasm adopting new technologies to innovate. The person will report to Senior Principal Data Scientist in HEOR-RWE and be focusing on building interactive applications on Amazon Web Services (AWS) Cloud, automating data pipeline, and facilitating training. In your role as a Data Science temp, you will use AWS Cloud cutting-edge technology to design/manipulate heterogenous data sets, and build or enhance applications in the areas listed below: Manipulate and merge data from different sources using programming language R or Python. Create and improve efficiency of data pipelines on AWS Cloud. Build data visualization dashboards and add features and functionalities using AWS QuickSight. You will gain experiences working on healthcare clinical trials development industry, develop data driven solutions to increase clinical research efficiency. You will be working closely with other members of our Data Science team to deliver value to our business partners. Prefer a degree in data science, statistics, applied analytics, computer science, engineering, or a related discipline. Curiosity and enthusiasm about data related techniques. Exposure to AWS Cloud technologies. Ability to program in Python, R or similar languages. Proficiency in writing SQL queries to join tables and manipulate data. Test and assess the quality of new tools. Eager to learn a new set of tools in AWS Cloud and work on challenging problems. Strong verbal and written communication and presentation skills. Able to work with internal clients with minimal supervision.\n",
      "Sales & Marketing experience, Asset Management a plus; Data Science/Data Analytics background  R and Python, a plus. BS / MS in Business Administration or Information Technology. Experience with Agile methodology, Jira experience a plus\n",
      "\n",
      "Original Contributions: Your innovations in AI, especially within the ChatGPT technology sphere, should stand out. We value original research, novel algorithms, or methodologies that have significantly influenced the domain. Published Work: Candidates should have significant publications in respected AI journals, platforms, or tech magazines. If your work is frequently cited, it speaks volumes about its importance. Awards and Honors: Distinctions in AI competitions, hackathons, or notable acknowledgments for your work will weigh in your favor. Media Attention: Your innovations should have been spotlighted by major media outlets, both traditional and digital. Speaking Engagements: Invitations to keynote at major AI events signify industry respect and recognition. Leadership Roles: Active roles in top AI organizations or research groups highlight your unmatched abilities in the field. Professional Affiliations: Being a member of elite AI and tech associations, especially those with rigorous membership standards, is a plus. Earnings Benchmark: If your compensation stands above your contemporaries, it reflects your unparalleled expertise. Commercial Impact: Your contribution to AI projects with noteworthy commercial success will be a strong selling point. Endorsements: Letters of recommendation from AI industry luminaries, detailing your specific impact, will bolster your profile. Academic Credentials: A robust academic background from elite institutions, particularly with a focus on AI, will be viewed favorably. Competence with Pictory and Synthesia platforms. Experience navigating Quillbot and the latest GPT Plugins\n",
      "Algorithm Development: Design, implement, and optimize machine learning algorithms and models using Python and relevant libraries/frameworks.  Data Processing and Analysis: Work with large datasets, preprocess and analyze data to extract meaningful insights that inform model development.  Software Development: Develop and maintain high-quality, scalable, and efficient Python code for AI and ML applications.  Integration: Integrate machine learning models into software applications and systems, ensuring seamless functionality and performance.  Collaboration: Collaborate with cross-functional teams, including data scientists, software engineers, and product managers, to deliver end-to-end solutions.  Model Deployment: Deploy machine learning models to production environments and contribute to the development of scalable and robust deployment pipelines.  Continuous Learning: Stay up-to-date with the latest advancements in AI and ML technologies, and contribute to the continuous improvement of team knowledge and capabilities.  Education: Bachelor's or higher degree in Computer Science, Data Science, or a related field.  Experience: Proven experience as a Python Developer. Demonstrated experience in developing and deploying machine learning models. Familiarity with popular machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. Skills: Strong proficiency in Python programming. Solid understanding of machine learning concepts and techniques. Experience with AI model deployment and integration. Knowledge of data preprocessing, feature engineering, and model evaluation. Excellent problem-solving and communication skills. Preferred: Master's or PhD in a relevant field. Experience with deep learning architectures. Knowledge of cloud platforms (e.g., AWS, Azure, or GCP).\n",
      "Create and maintain data flow design and technical requirements documentation using defined documentation templates that meets Agile product development standards (such as data analysis or methodology, MS Excel calculations). Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress Demonstrating the results of various algorithmic approaches and evaluating their performance Leverage a broad set of modern technologies including Python, R, Scala, and Spark to analyze and gain insights within large data sets and implement systems for automatic data collection, curation and model training Analyze diverse sources of data, extract features from data sources, train and test models, and Productionalize the models that significantly improve business outcomes. Works closely with Data Scientists and Data Engineers to develop predictive algorithms Training models and tuning their hyperparameters. Collaborate with other team members, subject matter experts, and delivery teams to deliver strategic advanced analytic based solutions from design to deployment Develop and maintain an understanding of relevant industry standards, best practices, business processes and technology used in modeling and within the financial services industry Manage own work with minimal oversight and proactively communicate status and risks to leadership 7+ years overall experience with 1-3 years in an ESG technology focused role within asset management or financial services industry. Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas. Experience with machine learning tools such as scikit-learn, R, Theano, TensorFlow, SparkML, or Foundry Experience in using two or more of the following modeling types to solve business problems: classification, regression, time series, clustering, text analytics, survival, association, optimization, reinforcement learning. Understanding of data models, large datasets, business/technical requirements, BI tools, statistical programming languages and libraries Demonstrates functional knowledge of data visualization libraries such as matplotlib or ggplot2; knowledge of other visualization tools such as Microsoft Power BI , Quick Sight or Tableau . Knowledge of cloud & computing technologies such as: Hadoop, Apache Spark, AWS, Microsoft Azure or Google cloud. Bachelor's or Masters degree in computer science, data science, statistics, mathematics, or a related field.\n",
      "This role is involved in conducting Lab studies. The studies involve blood. Should be comfortable working with blood. Should be able to independently execute studies. Need to have great lab skills, experience with data analysis, write reports & study protocols. Need to have wet lab skills such as pipetting and experience with in vitro studies. Day to day involves designing studies and attending team meetings, writing protocols, executing testing in the lab, doing data analysis and providing final reports. Generally, data analysis is done in Excel or Minitab, GraphPad. Experience doing data analysis in Excel or Minitab or GraphPad is a big plus. B.S./M.S. with minimum 2 years industry experience or a fresh Ph.D. (contingent on the Ph.D. being lab based). PhD should be from a related wet lab. Degree in Biomedical engineering or Biology is preferred. But if the candidate has a related degree but has worked in a biology lab with wet lab experience, they would be considered as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the thought of working with one of the most comprehensive employment data sets excite you?  Are you inspired by transformation and making an impact on the lives of millions of people every day? Are you a technologist first and foremost who approaches every problem wearing that hat while going out of your way to champion creativity and build diverse, productive, and engaged teams? Advanced Analytics & Predictive Modeling. You formulate analytical problems, extract & analyze data from multiple systems, summarize critical findings/insights, and develop a compelling visual representation of analyses with actionable recommendations. Team Collaboration. You will be part of a collaborative team, listening to needs, then finding and sharing solutions. You're comfortable and skilled at presenting your projects and findings to both peers and leadership. You collaborate with product, design, and engineering teams to plan, design, develop and deploy high-impact data products supporting multiple products across ADP. Research & Development. You design and implement start-of-the-art data products, machine learning models, and systems to optimize the HCM system user experience. You continuously looking for new ways to leverage ADP data to create new products and services and find more insights. You are passionate about learning and applying new techniques within data science that leads to innovations. Deliver at an epic scale. You write pristine code and documentation, champion and define best practices to produce highly adaptive, high-performing, continuous learning AI models/systems. May 2024 Graduates only  Education. Accepting three levels of education: Bachelor's Degree, Master's Degree and/or PH.D degree in Computer Science, Statistics, Engineering, or a related field. Communication. You are an advanced English language speaker. Technical skills. You have fluency in Python-including popular data science packages (pandas, sklearn, etc.), proficiency in SQL, notably writing and optimizing queries, and strong knowledge of data structures, algorithms, and methods used in the data science field. Knowledge of natural language processing Experience with integrating data products (recommender systems, classifiers, chatbots, etc.) into applications in production environments Exposure to Jupyter notebooks, MLflow, and/or Databricks platform AWS cloud solutions (S3, Glue, Lambda, SageMaker) Experience with distributed computing environments (Spark/Hive) Have courageous team collaboration. Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to find the best solution. Be surrounded by curious learners. We align ourselves with other smart people in an environment where we grow and elevate one another to the next level. We encourage our associates to listen, stay agile, and learn from mistakes.\n",
      " Collaborate with North America analytic asset stakeholders to identify requirements for asset deployment and model monitoring issues that may be loosely defined.   Work with the business, applications owners, solutions architects, and tech architects to understand the implications of respective data architectures to maximize the value of information across the organization.   Build the enterprise conceptual and logical data models for analytics, operational, and data mart structures by industry best practices models.   Identify, evaluate, and implement leading-edge data management frameworks required to address complex, large-scale data challenges.   Work within multi-functional agile teams with end-to-end product development and delivery responsibility.   Provide architectural support by building a process of concepts & prototypes.   You are a highly collaborative, creative, and intellectually curious   You can work well in a team.   You are adaptable and able to overcome technical challenges   You are a self-starter and motivated to learn and succeed.   You are data-driven and can identify problems as they arise.   Bachelor's degree in either, MIS, IT, Accounting, Finance, Marketing, Business, etc.   Working knowledge of Excel, PowerPoint, and Word is required.   Strong time management and organizational skills   Possess strong verbal and written communication skills and the ability to persuade and influence peers.   Experience with BI tools such as Qlik, Tableau, or Power BI. \n",
      " Should have worked on NF-Core, AirFlow, Nextflow  Should be able to create data management pipeline in Airflow  Should have good working knowledge of AWS (AWS Glue, AWS Omics, AWS Batch, Athena, EMR Serverless)\n",
      "Support the implementation of methods and development of tools to address confounding in claims or structured EHR data using R or SAS. Conduct feasibility analysis to identify and validate data sources and use cases. Conduct target literature searches Document programming and code specifics, support generating related reports, and ensure proper version control during the development of the scripts Strong understanding of epidemiological and/or statistical methods, version control, and working with medical/pharmacy claims and clinical EHR data in the pharmaceutical industry Prior experience real-world data (claims, EHR, registry, etc.) Proficient in SAS, R, SQL (proficient in python is a plus) R – Rstudio Workbench, Rstudio Connect, Rshiny, RSPM Familiar with survival analysis and related R packages (survival, flexsurv etc.) Experience in working with database (redshift, mySQL, etc.) Proficient with Git Good communication, writing and interpersonal skills Self-directed, proactive, and resourceful and capable or working with limited daily direction Exposure/familiarity working with life sciences companies\n",
      "Basic Oops Data Structures Advanced Math- Statistics, Algebra, Excel for data manipulation and visualization Database and SQL Computer Science/Engineering Background Basic Python - Variables, Data Types, Loops, Conditional Statements, functions, classes, file handling, exception handling, etc. Mathematics & Statistics: Linear Algebra Descriptive Statistics - Measure of central tendency (Mean, Median, Mode), Measure of dispersion (variance, standard deviation) Inferential Statistics - Hypothesis testing, correlation, covariance, Z-test, t-test, ANOVA test, etc. Probability - Central limit theorem, Probability distribution, bayes theorem etc. Data Handling and Manipulation using Numpy, Pandas, Scipy. Data Visualization using Matplotlib, Seaborn, Google Data Studio Feature engineering like imputing null values, handling outliers, scaling data. Introduction to frameworks like Scikit-Learn. Supervised Learning Introduction to both Regression and Classification problems. Train models using algorithms like Linear regression, logistic regression, Decision tree, random forest, SVC, KNN, etc. Evaluating models using metrics like RMSE, MAE, MSE, R2, accuracy, precision, recall, confusion matrix, F1-score etc. Unsupervised Learning Introduction to Clustering and Dimensionality Reduction problems. Learn unsupervised algorithms like K-Means, PCA, LDA, etc. Performance metrics like Elbow method, Silhouette Coefficient Regression - use cases like house price prediction, etc. Classification - use cases like email spam or not, etc. Unsupervised - use cases like anomaly detection, etc. Introduction to frameworks like Tensorflow, Keras for Deep Learning. What are Neural Networks and how do they function as the core of deep learning? Django Basics like creating projects, django views, mapping urls. Django Models to perform CRUD operations. Database operations Prompt Engineering Data Privacy - Context, Domain Best Practices- Token and Request optimization, Data Privacy considerations Tools - ChatGPT, Vertex AI, Dall-E2, GitHub Copilot, etc. Model Deployment using Cloud based platforms like GCP, Azure, etc. Testing Models and Data Pipelines ML Pipelines and ML workflows. Best Practices- cloud cost, Optimization of models GCP/Azure creating and deploying models, configuring VMs /GPU, Project : Install ML solution to GCP/Azure and update test data and rerun models Natural Language Processing: Dealing text data using NLTK, spacy framework. Introduction to algorithms like Lemmatization, stemming, NER, Word2Vec, etc. Computer Vision: Dealing with image data using OpenCV, PIL. Implement all the module learning and knowledge in a project like career coach, chatbot system, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Develop and mentor a team of data analysts to help tackle both operational & strategic questions facing the business Drive and oversee experiments and analyses to inform key strategic and operational decisions (promotional measurement, A/B testing of CRM campaigns, etc.) Create analytics infrastructure and standards, abstract complex problems into tangible milestones and guide the team to build on success (approach to segmentation, predictive LTV model, performance marketing attribution) Build tools, dashboard, reports to simplify day to day work of the business teams  Identify and clearly communicate actionable insights for stakeholders and executives Ensure key success metrics are identified and tracked to promote the team’s successes Stay informed on Industry BI/Analytics innovations and best-in-class practices Provide thought-leadership with all matters related to BI & Analytics as a Business Partner Bachelor's degree in Mathematics, Statistics, Operation Research or equivalent quantitative fields, MBA preferred 8+ years of sales, marketing or business analytics experience, including people management Exceptional communication and organizational skills Proficiency in SQL and programing languages like Python/R/Spark etc, and the ability to self-serve, investigate and get the data we require Self-starter and willingness to hustle in a fast-paced workplace A high-growth and rewarding role in a foundationally strong and rapidly evolving business Annual Salary Range: $175,000 - $235,000 plus annual bonus Excellent benefits including a 401K Match Paid Maternity, Adoption and Paternity leave And all the Nuts.com snacks your heart desires + a 40% employee discount\n",
      "Proven working experience as a Python Developer with machine learning skills Possess in-depth knowledge of object-relational mapping, experience with server-side logic, and above-average knowledge of Python programming and ML concepts Hands on experience with Django or Flask or other Python frameworks Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3 Familiarity with some ORM (Object Relational Mapper) libraries Basic Understanding of microservices, devops and cloud Strong analytical and problem-solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy Excellent communication skills Ability to work in a team At least a Bachelors Degree from an accredited university or equivalent experience in Computer Science or related field Understanding of Statistics concepts, AI and ML  US healthcare knowledge/experience will be an advantage\n",
      "Develop and deploy real-time multivariate monitoring models using statistical software to support the technology transfer and manufacturing of advanced therapies processes. Identify, develop and implement process improvement initiatives. Apply creative solutions to various data science projects. Provide technical support to process investigations. Create predictive models to help achieve optimal process performance. MS / BS in an engineering discipline (biomedical, chemical, biochemical, biostatistics etc.), or any life science equivalent in computational sciences Knowledge and experience in data analyses, visualization and report writing is required. Experience using either R or python; and git version control; and/or other statistical software. Knowledge of statistics and analyses (e.g. ANOVA, T-tests, Regression, Control Charts) Experience with pharmaceutical drug substance & drug product manufacturing processes is a plus. Excellent communication skills, both oral and written Team player: working in cross-functional teams.\n",
      "Ad hoc analyses utilizing secondary data sources  Process and analyze performance trends through automated dashboards  Collaborate with key internal and external partners on national and subnational reporting deliverables  Conduct deep dives and targeted analytics to answer critical business questions that arise from the weekly and monthly performance results  Analytical mindset and comfort conducting analyses using large amounts of data is required  Proficiency with Microsoft applications (Excel, PowerPoint) is required  Experience utilizing dashboards and data visualization software (Tableau and/or Dataiku) is preferred but not required  Experience in pharma data (patient, physician, claims, etc.), data integration, and pharma analytics/metrics is preferred but not required \n",
      "Develop and execute a comprehensive data strategy aligned with the company's goals and objectives Establish and maintain data governance policies, procedures, and standards to ensure data quality, privacy, and security. Oversee the collection, integration, and management of healthcare data from diverse sources, including electronic health records (EHRs), clinical trials, genomics data, and more. Lead a team of data scientists and analysts to derive actionable insights from healthcare data, providing valuable information to support clinical decision-making and patient care. Implement robust data security measures to safeguard patient information and maintain compliance with relevant regulations, such as HIPAA. Collaborate with cross-functional teams, including technology, clinical, and business development teams, to drive data-driven solutions and innovations Manage relationships with external data providers and partners to ensure access to high-quality healthcare data. Create and present regular reports and updates to senior management and stakeholders. Bachelor's degree in a related field (e.g., Health Informatics, Data Science, Healthcare Management). Advanced degree preferred. 7+ years of experience in healthcare data management, with at least 3 years in a leadership role Strong knowledge of healthcare data sources, including EHRs, claims data, and clinical trial data. Familiarity with healthcare data standards and regulations, including HIPAA. Proven experience in data strategy development and execution. Excellent leadership and team management skills. Strong analytical and problem-solving abilities. Exceptional communication and presentation skills. Ability to work collaboratively in a fast-paced, innovative environment.\n",
      "Experience with data management and data governance practices Bachelor’s degree in STEM (Science, Technology, Engineering, Mathematics) Strong skills in troubleshooting, performance tuning, security, backup/recovery, and monitoring of large database management systems Ability to independently run technical projects and directly interface with the business and vendors Good interpersonal skills, written and verbal communication Strong analytical and problem-solving skills. Ability to independently troubleshoot and resolve Advanced knowledge of Data Management tools, techniques, and programing languages Demonstrates general understanding of overall data models, data relationships, mapping lineage and business rules Experience performing data analytics, managing complex SQL queries and working with BI platforms such as Alteryx or PowerBI Experience with data profiling & data quality, recommending improvements to best practices Proven track record in the Property & Casualty insurance industry Experience with Salesforce, Salesforce Velocity, Instec or other Policy administration systems is a plus Experience with data management and data governance practices Bachelor’s degree in STEM (Science, Technology, Engineering, Mathematics) Strong skills in troubleshooting, performance tuning, security, backup/recovery, and monitoring of large database management systems Ability to independently run technical projects and directly interface with the business and vendors Good interpersonal skills, written and verbal communication Strong analytical and problem-solving skills. Ability to independently troubleshoot and resolve Advanced knowledge of Data Management tools, techniques, and programing languages Demonstrates general understanding of overall data models, data relationships, mapping lineage and business rules Experience performing data analytics, managing complex SQL queries and working with BI platforms such as Alteryx or PowerBI Experience with data profiling & data quality, recommending improvements to best practices Proven track record in the Property & Casualty insurance industry Experience with Salesforce, Salesforce Velocity, Instec or other Policy administration systems is a plus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming Skills: The data scientist demonstrates proficiency in programming languages such as Python or R. They write efficient and clean code to manipulate, analyze, and visualize data. Statistical Analysis: The data scientist possesses a strong foundation in statistics, understanding concepts like hypothesis testing, regression analysis, probability theory, and statistical modeling techniques. Machine Learning: The data scientist is familiar with machine learning algorithms and techniques, understanding supervised and unsupervised learning, feature engineering, model evaluation, and optimization. Data Manipulation and Cleaning: The data scientist has expertise in handling large datasets, cleaning data, and performing data preprocessing tasks. They use tools like pandas, NumPy, or dplyr to manipulate and transform data effectively. Data Visualization: The data scientist effectively communicates insights and findings through visual representations. They demonstrate proficiency in data visualization libraries and tools like Matplotlib, Seaborn, or Tableau. SQL and Databases: The data scientist understands structured query language (SQL) and works with databases proficiently. They extract, manipulate, and analyze data stored in relational databases efficiently. Big Data Technologies: The data scientist has knowledge of big data technologies like Apache Hadoop, Apache Spark, or distributed computing frameworks. They work with large-scale datasets and leverage distributed computing for data processing.\n",
      "Working on machine learning projects  Analyzing and processing data to create machine learning models  Implementing and optimizing machine learning algorithms  Testing and evaluating models  Collaborating with the programming team and other departments within the company to develop innovative solutions  Minimum 2 years of experience in the field of machine learning  Knowledge of machine learning algorithms and techniques  Ability to analyze and process data  Familiarity with machine learning tools and technologies  Proficient in English communication  Education in computer science  B2B contract type  Full-time employment  Remote and flexible working hours\n",
      "Collaborate with the data science team to develop and implement predictive models for customer attrition analysis. Assist in designing and implementing document intelligence models to extract valuable insights from unstructured data sources. Conduct exploratory data analysis to identify patterns, trends, and correlations within large datasets. Support data cleansing, preprocessing, and feature engineering tasks to ensure data quality and relevance for analysis. Participate in model evaluation, validation, and optimization processes to enhance predictive performance. Communicate findings and insights effectively through visualizations, reports, and presentations. Stay updated on industry trends, best practices, and emerging technologies in data science and analytics. Must be enrolled in a Bachelors (as a rising Junior or Senior) or Master’s program in Statistics, Data Science, Mathematics, Computer Science or a related field Solid understanding of data science concepts and techniques, including machine learning, statistical analysis, and data visualization. Proficiency in programming languages such as Python or R for data manipulation and analysis. Familiarity with data manipulation libraries (e.g., pandas, NumPy), machine learning frameworks (e.g., scikit-learn, TensorFlow, PyTorch), and data visualization tools (e.g., Matplotlib, Seaborn, Plotly). Strong analytical and problem-solving skills, with the ability to translate business requirements into data-driven solutions. Excellent communication and collaboration skills, with the ability to work effectively in a team environment. Prior experience or coursework in finance, economics, or related fields is a plus.\n",
      "You can actively contribute to our clients’ mission of advancing scientific discoveries that have the potential to change patients' lives for the better. Our PEOPLE FIRST culture prioritizes personal and professional growth for all Vitalief employees. We give everyone a seat at the table – we encourage innovation. Life/work balance that includes 20 PTO (Paid Time Off) days plus 9 paid Holidays annually. Other benefits include Company paid life insurance and short / long term disability coverage; 401K retirement program; Robust healthcare plans to choose from. Reporting to a Program Manager, this resource will support a medication-assisted treatment and recovery support services program for individuals with substance use disorders in northern New Jersey; more specifically in developing data-driven decision-making processes. Design and implement systems to track program deliverables, ensuring data quality, and contributing to on-going sponsored projects and opportunities for research. Works with leadership, clinical manager, academic detailers and training specialist to identify key performance indicators, benchmarks, and establish data collection methodologies. Develop a system using data visualization tools (i.e. Tableau, Qualtrics, etc.) to track and analyze academic detailing and training services. Most of the data to be analyzed will relate to educational workshops and training. A small portion of the data will be collected from EMR and patient charts. Assist in development of research methodologies and data collection strategies. Implement data collection tools, monitor and assess data quality, and ensure the integrity and accuracy of collected data. Conduct data analysis to identify trends, correlations, and areas for improvement. Analyze research data and contribute to preparation of research reports, publications, program materials and documents. Design and produce data dashboards and infographics for a diverse audience of users. Bachelor’s Degree in Public Health or related field. Master’s Degree in Public Health is a big plus. 2 to 4 years of data analysis experience, preferably in an educational or research setting in the public health field. Strong knowledge of data visualization techniques and tools (experience with Tableau and/or Qualtrics is preferred). Proficiency in data analysis and report generation. Self-starter that thrives in a fast-paced work environment. Ability to train a team about what is possible through data and statistical analysis. Must have strong communication, presentation and interpersonal skills, with the ability to convey complex data insights to non-technical terms. Excellent analytical skills, attention to detail, and the ability to work independently and collaboratively with multidisciplinary teams.\n",
      "\n",
      "Advising on appropriate statistical and programming approaches to answering key research questions as identified by therapeutic area research experts. Conducting and/or supervising statistical analysis and database programming for RW data analytics that are intended for external publication and regulatory submission. Generate high quality, readily interpretable deliverables (e.g., data tables, graphs, charts, study reports) Use of statistical techniques including regression modeling, mixed models, survival analysis, propensity score matching/modeling and non-parametric methods. Performing health economics and outcomes, and comparative effectiveness analyses. Interacting and advising/consulting with external collaborative partners on joint projects. A minimum of a master’s degree is required in a relevant discipline such as biostatistics, economics, epidemiology, mathematics, public health, or health. Three to Five years of relevant analytic and coding experience is required. Professional programming skills R and R Markdown. Experience with SAS and / or SQL is also strongly preferred. Academic training and industry or payer experience in statistics, health economics, and outcomes research is highly preferred. Experience with analytics, coding and management of administrative claims datasets, electronic health/medical records and/or clinical registry data is highly preferred. Understanding of claims database and Electronic Health Records (EHR) is highly preferred. Knowledge of medical terminologies (e.g., ICD, NDC, GPI, SNOMED, MedDRA, LOINC, CPT) is preferred. Self-motivation, self-initiation, and ability to meet deadlines are required. Ability to plan, organize, and work on multiple tasks simultaneously in different projects are required. Strong written and oral communication skills are required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Working closely with business stakeholders, product managers, and data engineers to design,  Developing, training, tuning, and optimizing AI models and algorithms.  Implementing complex real-time data and AI/ML applications to capture and codify  Developing ML/AI models for business teams along with metrics to track their accuracy  Overseeing the full lifecycle of ML model development from ideation and data exploration, algorithm design and testing, model development, tests and registrations, model versions managements, to monitoring and tuning in production.  Evaluating ML algorithms that could be used to solve a given problem and ranking them by their success probability.  Acting as an internal resource for AI/ML specific needs, providing guidance, analysis, and context to internal stakeholders during meetings and other strategy activities.  Machine Learning;  Familiar with MLFlow, Kedro, Pyspark, Pytorch frameworks (Over 5 years)  Expertise of using commonly used ML/AI Models/libraries such as Pandas, Numpy, Tensorflow2/3, Keras, BERT, LayoutLMV1/2/3 as well as regressions, decision trees, random forest, K-means, etc traditional ML algorithms. (Over 10 years)  Expertise of distributed ML/AI training libraries/models: Koalas, Horovod, DDP.   Python programing and Software Engineering  Expertise of Pythonic clean coding, developing decorators, generators and descriptors for Python modules/libraries (over 10 years)  Expertise of Software Design by Contract, particular over 10 years of DRY/OAOO, YAGNI, KIS, EAFP/LBYL, Defensive programming  Expertise of separating cohension and coupling concerns in software design. (Over 10 years)  Expertise of structing the code and orthogonality in software. (Over 10 years)  Expertise of the SOLID Principles (Single responsibility, Open/closed, Liskov’s substitution, Interface segregation and Dependency Inversion) (Over 10 years) Cloud DevSecOps  Over 5 years of coding container image dockfile and K8S  Over 5 years of coding YAML scripts  Expertise of building CI/CD pipelines, particular over 10 years of programming in Jenkins, Github, Nexus, Sonar, Unit test framework, Pytest.  Over 5 years of Cloud, familiar with at least 2 of Azure, GCP and AWS.   Familiar with node affinity, container, pods, namespace and cluster (over 5 years)  Over 5 years of protecting data in production using Key-vaults, cloud HSM, KMS. \n",
      " Client is one of the largest global medical technology companies in the world and is advancing the world of health by improving medical discovery, diagnostics, and the delivery of care. We have over 65,000 employees and a presence in virtually every country around the world to address some of the most challenging global health issues.   In today’s fast evolving medical technology world, one aspect remains common – reliance on data to drive the next wave of innovation. The Data Scientist in HEOR-RWE will help advance client’s Real-World Evidence (RWE) strategy and help build the right analytics strategy for a range of Business Units and Functions.   We are looking for a Data Science temp who is passionate about data and analysis tools, has the rigor needed to solve problems, and demonstrates curiosity and enthusiasm adopting new technologies to innovate.   The person will report to Senior Principal Data Scientist in HEOR-RWE and be focusing on building interactive applications on Amazon Web Services (AWS) Cloud, automating data pipeline, and facilitating training.   In your role as a Data Science temp, you will use AWS Cloud cutting-edge technology to design/manipulate heterogenous data sets, and build or enhance applications in the areas listed below:   Manipulate and merge data from different sources using programming language R or Python.   Create and improve efficiency of data pipelines on AWS Cloud.   Build data visualization dashboards and add features and functionalities using AWS QuickSight.   You will gain experiences working on healthcare clinical trials development industry, develop data driven solutions to increase clinical research efficiency. You will be working closely with other members of our Data Science team to deliver value to our business partners.   Prefer a degree in data science, statistics, applied analytics, computer science, engineering, or a related discipline.   Curiosity and enthusiasm about data related techniques.   Exposure to AWS Cloud technologies.   Ability to program in Python, R or similar languages.   Proficiency in writing SQL queries to join tables and manipulate data.   Test and assess the quality of new tools.   Eager to learn a new set of tools in AWS Cloud and work on challenging problems.   Strong verbal and written communication and presentation skills.   Able to work with internal clients with minimal supervision.   Fluent written and spoken English   Hybrid\n",
      " The position includes working full-time from our NJ office ** Please do not apply if you are not local to the Northern Jersey area.  ﻿Collaborate closely with cross-functional teams to understand business objectives and identify analytical requirements. Design, build, and maintain business dashboards and reports using SQL, Looker, and BigQuery. Perform data extraction, transformation, and loading (ETL) processes. Conduct thorough data analysis to derive actionable insights and recommendations. Present findings to stakeholders through clear and compelling visualizations and reports. Continuously learn and stay updated with industry trends and best practices in data analysis. Bachelor’s degree in Data Science, Statistics, Computer Science, or a related field. Strong proficiency in SQL for complex querying and data manipulation. Experience with data visualization tools, particularly Looker, is highly desirable. Familiarity with Google BigQuery or similar big data platforms is a significant plus. Excellent analytical and problem-solving skills. Strong communication skills, both written and verbal. Ability to work in a fast-paced environment and manage multiple projects simultaneously. A strong desire to learn and grow, coupled with a deep interest in understanding business processes and needs. Competitive Medical, Dental, Vision Company 401k Match 20 PTO days, Company paid holidays Career growth as we scale across the US\n",
      "\n",
      " Design, develop, and implement machine learning models for various applications.   Collaborate with cross-functional teams to understand project requirements and deliver robust AI solutions.   Evaluate and experiment with different machine learning algorithms to optimize model performance.   Work on data preprocessing, feature engineering, and model deployment.   Stay updated on the latest advancements in AI/ML and incorporate relevant technologies into projects.   Bachelor's/Master's/Ph.D. degree in Computer Science, Machine Learning, or a related field.   Proven 5+ years of experience in developing and deploying machine learning models.   Strong programming skills in languages such as Python and or C#.   Familiarity with popular machine learning frameworks (e.g., TensorFlow, PyTorch).   Experience with data preprocessing, feature engineering, and model evaluation.   Solid understanding of statistics, mathematics, and algorithms.   Experience with deep learning and neural networks.   Knowledge of natural language processing (NLP) techniques.   Familiarity with cloud platforms (e.g., Azure).  Must be able to commute to the Iselin NJ office 3-4 days per week Qualified applicants must be able to work for any employer in the US without sponsorship.   Competitive compensation   Comprehensive healthcare benefits which include:   Medical, Dental and Vision   Life insurance   Employee assistance program   Paid training   A generous PTO program   401k plan supported by a company match   Work-life balance   Long term stability in a fast-growing industry   The satisfaction of knowing they are working for an organization leading the way in clean energy initiatives   And Much MORE! \n",
      "Executes standard software solutions, design, development, and technical troubleshooting Writes secure and high-quality code using the syntax of at least one programming language with limited guidance Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems Adds to team culture of diversity, equity, inclusion, and respect Formal training or certification on software engineering concepts and 5+ years applied experience Programming experience in Java, Python, Groovy, Scala, JavaScript, ReactJS Hands on experience with BigData and distributed computation systems (HDFS, Spark, Apache Flink, Databricks) Hands on experience with SQL and NoSQL databases Experience building applications on AWS, Spring Boot and Cloud native foundations Experience across the whole Software Development Life Cycle Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.) Data Modeling skill Experience building AI/ML based applications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly Performance and execution reporting development and internal business usage reports Ad-Hoc Analysis requests and Program set up and Performance tracking Pricing models and Monthly leadership performance reviews (individual presentation and design support)  Strong analytical and report generation skills, including data validation and enhancement design  1+year experience with Microsoft Office suite including excel, Outlook, Teams, PowerPoint, etc.  1+year experience with data analysis and reporting design  1+year experience with data mining, query writing, and data visualization tools (SQL, Snowflake, and power bi/Tableau, etc.)  Developed project management and operational workflow understanding and skill set  Familiarity with process improvement/ Lean / continuous improvement methods  Quick learner and is able to digest information and direction and apply to individual tasks  Either already knows or has the ability to quickly learn the retail pharmacy and operations side of the business  Experience with automation and technology enhancement integration and performance tracking  Influence leaders at different levels  Communicate and present information clearly and succinctly  Build partnerships and leverage interpersonal skills  Read and understand P&L or other tracking data  Regular and predictable attendance  Additional tasks as directed by manager\n",
      "Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Project work on the technologies needed Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools Excellent written and verbal communication skills\n",
      "Review project documentation before delivering to clients. Execute Quality System processes (CAPA, Deviations, audits, training, calibration, document control, records management) under the guidance of the Quality Manager. Identify and address QMS gaps and propose improvements. Maintain cGMP compliance following established SOPs. Foster open communication with colleagues. Assist in investigations and corrective actions. Support Data Integrity initiatives. Perform other duties as assigned. Preferably, a Bachelor of Science (BS) degree. Strong communication skills, both written and oral. Attention to detail and ability to multitask. Effective communication across the organization.\n",
      "Currently pursuing a PhD degree in Statistics, Biostatistics, Data Science, Computer Science, Electrical Engineering, Computational Biology, Biomedical Informatics, or related quantitative discipline. Strong working knowledge of data mining and machine learning. Proficiency in one or more of the following programming languages: Python, R. Familiarity with predictive modeling and analysis of large datasets. Strong technical communication and presentation skills. Experience with processing and analyzing sensor or wearable device data.  Experience with semi-supervised and/or self-supervised learning. Experience with Large Language Models Proficiency in Python programming language.\n",
      "Working on machine learning projects  Analyzing and processing data to create machine learning models  Implementing and optimizing machine learning algorithms  Testing and evaluating models  Collaborating with the programming team and other departments within the company to develop innovative solutions  Minimum 2 years of experience in the field of machine learning  Knowledge of machine learning algorithms and techniques  Ability to analyze and process data  Familiarity with machine learning tools and technologies  Proficient in English communication  Education in computer science  B2B contract type  Full-time employment  Remote and flexible working hours\n",
      "Review of Clinical Trial Data: Evaluate Case Report Forms (CRFs), Monitoring Reports, and other relevant documents. Draft Listings and Tables: Collaborate in the creation and review of draft listings and tables related to clinical trial data. Query Resolution: Identify and propose queries to rectify inconsistencies or errors in completed Case Report Forms. Data Verification: Validate all data in the study database against information provided in relevant documents, ensuring accuracy and completeness. Review Comment Fields: Scrutinize comment fields in Case Report Forms for potential inclusion in study databases. Narrative Review and Preparation: Assess narratives for accuracy, completeness, and clinical relevance. Prepare draft narratives as required. Clinical Document Preparation: Contribute to the preparation of clinical trial reports and other essential clinical documents. Project Timeline Management: Take a lead role in managing project timelines, ensuring adherence to deadlines, and providing regular status updates to relevant stakeholders. Continuous Learning: Maintain and expand expertise relevant to the position and project responsibilities, staying abreast of industry advancements and best practices. Ad Hoc Activities: Perform other activities as requested by the project team or management. Bachelor’s degree with a minimum of 3 years of pharmaceutical industry experience or an experienced Registered Nurse (R.N.) with clinical research exposure. Excellent written and oral communication skills. Proficiency in reviewing and interpreting clinical trial data and related documents. Strong organizational skills with the ability to manage project timelines effectively.\n",
      "\n",
      "Data Analysis and Interpretation: Utilize advanced data science techniques to analyze large datasets, including the VA's electronic health record, to identify trends, patterns, and insights related to military environmental exposures. Apply statistical analysis methods to evaluate the effectiveness of clinical trials and their impact on Veterans' health outcomes. Program Evaluation and Research: Expand our program evaluation and research portfolio by applying clinical/health informatics expertise to assess the implementation of the PACT Act (Patient Aligned Care Team Act). Collaborate with interdisciplinary teams to design and execute research studies, collect relevant data, and analyze the results to ensure that the needs of Veterans and their providers are met effectively. Reporting and Communication: Prepare comprehensive reports and presentations summarizing the findings from data analysis and research studies. Clearly communicate complex concepts and results to stakeholders, including Veterans, policymakers, providers, and researchers, in a manner that is accessible and actionable. Collaboration and Partnerships: Collaborate with internal and external stakeholders, including fellow researchers, clinicians, and data scientists, to exchange knowledge, share best practices, and leverage expertise in clinical/health informatics. Foster partnerships with relevant organizations and institutions to enhance research capabilities and access to data resources. Continuous Learning and Professional Development: Stay abreast of the latest advancements in clinical/health informatics, data science, and statistical analysis methodologies. Actively participate in professional development activities, such as attending conferences, workshops, and training sessions, to enhance skills and knowledge. Master's or Ph.D. degree in a relevant field such as Clinical Informatics, Health Informatics, Biostatistics, Data Science, or a related discipline. Strong proficiency in quantitative analysis, data science techniques, and statistical analysis methodologies. Experience working with large healthcare datasets, preferably including the VA's electronic health record. Proficiency in data manipulation and analysis using programming languages such as Python, R, or SAS. Knowledge of clinical trials, program evaluation, and research methodologies. Excellent communication skills with the ability to convey complex information to diverse audiences. Strong problem-solving abilities and attention to detail. Ability to work collaboratively in interdisciplinary teams and effectively manage multiple projects simultaneously.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You will conduct research, design, and implement AI algorithms for medical imaging - diagnosis, therapy planning and prediction.  You will conduct research, design, and implement AI algorithms for medical imaging - diagnosis, therapy planning and prediction  Strong background in computer vision and machine learning, medical imaging background is preferred  Experience with deep learning libraries like Tensor flow, PyTorch  Strong communication and collaboration skills  Currently enrolled in a PhD program\n",
      "Work with business stakeholders and IT teams to analyze and resolve data issues for the enterprise data warehouse. Create source (OLTP applications) to target (DWH) mapping documents to capture additional application data elements. Load the source-to-target mapping documents from source systems into the enterprise data warehouse. Collaborate with the ETL team to ensure the source-to-target mapping documents are in correct ETL code. Ensure the ETL code align with STM requirements. Perform data validation, to insure correct data movement into the enterprise data warehouse architecture. Consult with reporting teams to develop a general understanding for the data warehouse model / optimal ways to use it. Proven 5+ years’ experience of data analysis – extraction of OLTP data within an enterprise data warehouse. Possess 5+ years of Policy & Claims Insurance subject-matter expertise.  Candidate has advanced level SQL knowledge. Possess optimal knowledge for concepts and frameworks for Data Warehousing, ETL, and BI Architectures. Candidate is capable of creating and tuning Semantic layer Reporting Views. Able to facilitate data discovery sessions, which will include an audience of business subject-matter experts. Proven knowledge of RDBMS platforms (e.g., SQL Server, DB2), with experience in generating DDL. Possess knowledge of Guidewire Policy Center, Guidewire Claims Center, SAP FS-RI & SAP FS-CD applications with their data is considered a plus.\n",
      " Post 9/11 Military Veteran with an Honorable discharge, OR currently serving in the National Guard/Reserve  We are looking for an individual who already has or is pursuing a B.S. degree in Data Science, Computer Science, Information Systems, Mathematics, Statistics, or a related field Technical Skills: Proficiency in data analysis tools. Intermediate to Advanced in Microsoft Excel. Experience using pivot tables and creating Dashboards. Experience with data visualization tools - Tableau is the daily tool used. Training on Tableau may be provided to those with only Power BI experience. Communication: Strong written and verbal communication skills, with the ability to use Data Analysis language in a clear and concise manner. A major function of this role will be presenting Dashboards to Stakeholders and management. Presentation Skills: Proficient in presentation skills with a proven track record of creating and delivering impactful presentations to stakeholders. Analytical Thinking: Strong analytical and problem-solving skills, with the ability to derive insights from complex datasets and communicate findings effectively. Attention to Detail: Keen eye for detail and a commitment to maintaining data accuracy and meeting strict deadlines. Team Player: Excellent interpersonal and collaboration skills, with the ability to work effectively in a team-oriented environment. Adaptability: Ability to adapt to a fast-paced, dynamic environment and manage multiple tasks simultaneously. Data Analysis: Collect, organize, and analyze large volumes of data using appropriate tools and techniques. Tableau Dashboard creation. Data Interpretation: Identify patterns, trends, and anomalies within the data, and develop insights that can be used to inform security strategies and risk mitigation efforts. Reporting: Prepare comprehensive reports and presentations summarizing data analysis findings, including key metrics, trends, and recommendations. Process Improvement: Collaborate with team members to identify areas for process improvement, automation, and optimization of data analysis workflows. Compliance Monitoring: Monitor compliance with internal security policies, industry regulations, and best practices, and provide recommendations for remediation as necessary. Documentation to support compliance will be provided by Johnson & Johnson. Collaboration: Work closely with cross-functional teams, to ensure effective data analysis Professional Development: Stay up-to-date with the latest trends, techniques, and tools in data analysis and risk management to enhance your skills and knowledge. Full-Time  $27.00/Hour (plus Benefits) Free Individual Health Insurance Free Training (Program specific) Paid Vacation Paid Company Holidays Individual Mentor  Interest free loans (Case basis) Raritan, NJ\n",
      "Develop novel solutions to market-driven problems using your knowledge of the latest AI/ML/NLP techniques, rigorous statistical analysis, and practical experience on previous data science projects. Maintain existing analytic products and support Sales and Implementation teams in their use Serve as a Subject Matter Expert on data, analytics and AI models within the Sales and Marketing, Supply Chain Management, Compliance, Risk and other lines of business consulting with business and product groups, on modeling and analytic solutions. Help build new data science capabilities. Guide and mentor junior analysts. Enjoy and share academic literature, technical developments, and industry best practices. Identify business relevance of new methods and work with cross functional teams to create prototypes, assist in creating business cases. Collaborate with internal and external stakeholders (external customers, other D&B data scientists, sales team members, business unit product leaders and development teams) to understand business needs and technical requirements through direct, external consultative customer engagements as well as proof-of-concept implementations for products. Participate and support other teams, as needed, for all aspects of model development, including design, model implementation, validation, calibration, documentation, product implementation, monitoring, and reporting. Derive actionable insights from unconventional big data, using a variety of analytic techniques to identify impact on use cases and assess incremental value (in terms of lift in predictive power). Research complex business issues and recommend solutions, including customer data input requirements, other required data sets, and best modeling approaches. Master's degree in a quantitative / applied field (Engineering, Computer Science, Data Science, Operations Research, Mathematics, Statistics, Econometrics).  Experience with programming and modeling using Python, PySpark, Scala. Experience collaborating, including the ability to build and maintain relationships with internal and external stakeholders/clients, and being disciplined in delivery of initiatives. Proficient SQL skills and experience working with large data sets (big data, IoT data). Experience applying current machine learning techniques Knowledge of evolving data science concepts and best practices Experience communicating complex ideas to both a technical and non-technical audience. Creative and inquisitive in nature. Thrives on change Flexibility to master and apply new analytic tools.  Generous paid time off in your first year, increasing with tenure.  Up to 16 weeks 100% paid parental leave after one year of employment.  Paid sick time to care for yourself or family members.  Education assistance and extensive training resources.  Do Good Program: Paid volunteer days & donation matching.  Competitive 401k & Employee Stock Purchase Plan with company matching.  Health & wellness benefits, including discounted Gympass membership rates.  Medical, dental & vision insurance for you, spouse/partner & dependents.  Learn more about our benefits: http://bit.ly/41Yyc3d .\n",
      " Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT  Highly motivated, self-learner, and technically inquisitive  Experience in programming language Java and understanding of the software development life cycle  Project work on the skills  Knowledge of Core Java, JavaScript, C++ or software programming  Spring boot, Microservices, Docker, Jenkins and REST API's experience  Excellent written and verbal communication skills  Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT  Project work on the technologies needed  Highly motivated, self-learner, and technically inquisitive  Experience in programming language Java and understanding of the software development life cycle  Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools  Excellent written and verbal communication skills\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Develop and validate models to optimize the Who, When, Where and How of all our interactions with customers  Develop Amazon-scale data engineering pipelines  Imagine and invent before the business asks, and create groundbreaking applications using cutting-edge approaches  Develop compelling data visualizations  Work closely with other data scientists, ML experts, engineers and on cross-disciplinary efforts with other scientists within Amazon  Contribute to the growth of the Audible Data Science team by sharing your ideas, intellectual property and learning from others  Modeling, research design experience  MS in one of the following disciplines: Computer Science, Statistics, Data Science, Economics, Applied Math, Operational Research or a related quantitative field  3 yrs relevant experience; or, PhD +1 yr relevant experience  Fluent in SQL, Python  Experience in Machine Learning Pipeline orchestration with AWS (SageMaker, Batch, Lambda, Step Functions) or similar cloud-platforms  Expereince in Big Data Engineering with Spark / AWS EMR & Glue  Experience with Agile Software Development  Domain knowledge and expertise of paid marketing, specifically in Paid Search and Organic Search  Experience with Container Platforms (Docker, Kubernetes/Fargate)  Experience with Streaming data processing  Experience with R, RShiny, and Scala\n",
      "Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Knowledge of Core Java , javascript , C++ or software programming Spring boot, Microservices and REST API's experience Excellent written and verbal communication skills Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT Highly motivated, self-learner, and technically inquisitive Experience in programming language Java and understanding of the software development life cycle Knowledge of Statistics, Python, data visualization tools Excellent written and verbal communication skills\n",
      "\n",
      "Must work with business team to understand requirements, and translate them into technical needs Gather and organize large and complex data assets, perform relevant analysis  Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) Propose and implement relevant data models for each business cases Optimize data models and workflows Communicate results and findings in a structured way Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements Leverage existing or create new \"standard pipelines\" within to bring value through business use cases Ensure best practices in data manipulation are enforced end-to-end Actively contribute to Data governance community Knowledge of AWS Knowledge of Azure or GCP is a plus Orchestration: Airflow Project management & support: JIRA projects & service desk, Confluence, Teams Expert in ELT and ETL such as Informatica IICS, Databricks, Delta, Glue, ..  Expert in Relational database technologies and concepts: Perform SQL queries Create database models Maintain and improve queries performance Snowflake is a plus Working knowledge of Python and familiar with other scripting languages Good knowledge of cloud computing Pragmatic and capable of solving complex issues Ability to understand business needs Good communication Push innovative solutions Service-oriented, flexible & team player Self-motivated, take initiative Attention to detail & technical intuition At least 5 years experiences in a data team as Data Engineer Experience in a healthcare industry is a strong plus BS or MS in Computer Science\n",
      "Cultivating an understanding of the role of EGDS in the pharmaceutical industry – how an EGDS department may be structured, how EGDS interacts with specific departments within the company, and how EGDS within MNK may interact with entities outside the company (e.g., vendors, KOLs, etc.)  Improving scientific writing skills / delivering EGDS publications support, including communicating EGDS information to internal business partners  Engaging in ongoing and new EGDS research projects as an EGDS researcher, reviewing and providing input on study design, data analysis and results, QA of research documents, and/or engaging with study teams and other MNK personnel as needed  Conducting literature search/review re: unmet needs, treatment guidelines, impact of treatment on clinical, economic, patient-reported outcomes, etc.  Participating in regular EGDS department and cross-functional meetings  Developing/Presenting (PowerPoint slides) on research-related topics to an extended or cross-functional team  Education/Experience: Has at least two years of Graduate study, PhD student preferred  Preferred Skills/Qualifications: Proficiency in Microsoft Word, Excel, and PowerPoint  Has completed 1yr of coursework in Epidemiology, Research Methodology, Data Science, Statistics, Health Policy, and Economic Analysis, a plus  Has excellent writing and oral communication skills  Ability to work on project teams  Has acquired skills/experiences in data analysis using statistical packages (SAS or R preferred) and/or literature review/search using Medline/PubMed, a plus \n",
      "Understand the medical context and formulate clinical challenges into machine learning problems Integrate state-of-the-art AI for optimizing and advancing on existing clinical data Develop innovative solutions regarding real clinical challenges and do large-scale validation Potential contribute to high-impact publications Strong motivation to solve practical problems Hands on coding skills with deep learning especially generative AI and knowledge of libraries like PyTorch Strong communication and collaboration skills Strong publication record is a plus  Currently enrolled in a Ph.D.  Minimum 3.0 GPA (preferred)\n",
      "Research and develop advanced machine learning and AI techniques and algorithms Evaluate algorithm performance using real-life and simulated data Author research papers and patents Currently been a Ph.D. candidate in Statistics, Computer Science, or Electrical Engineering, Developed novel statistical and machine learning algorithms Trained and evaluated the performance of AI models  Strong algorithmic problem-solving and software development skills (Python) Published paper(s) in peer-reviewed venues Demonstrated capability to develop proof-of-concept prototypes for experimenting with novel algorithms Strong written and verbal communication skills Disclaimer: Benefits do not apply to student, intern, or Co-op positions. Specific terms and conditions for internships and co-op programs will be outlined separately.  One of the World’s Most Ethical Companies by Ethisphere   Gender-Equality Index by Bloomberg   Workplace Pride Global Benchmark  Pension Plan - Cash Account Program Medical and dental coverage Short term disability and long-term disability Life insurance and AD&D – Company paid 2 x base pay Supplemental life and AD&D insurance (Employee/Spouse/Child) Health care and dependent care Flexible Spending Accounts Pre-tax commuter and parking benefits Savings/401(k) Plan Paid time off for holidays and vacation Employee Stock Purchase Plan Tuition Assistance Plan Adoption assistance Employee Assistance Program/Work Life Resource Program Voluntary benefits including vision, legal, auto & home Insurance, pet insurance, Identity Theft Protection Services, and Health Advisory Services” Nokia Perks At Work\n",
      "Graduate degree in a relevant field (Computer Science, Mathematics, Electrical Engineering) 4+ years of industry experience in designing, building, and deploying NLP models (note: internships and school work do not count)  Experience in applying transformer-based deep-learning techniques to challenging NLP problems   Fluency in Python and experience with Python-based ML frameworks such as PyTorch and HuggingFace   Outstanding communication skills  Publications in top-tier NLP conferences Experience with distributed ML frameworks such as DeepSpeed and FSDP  Background in computational linguistics  Design, build, evaluate, and deploy algorithms and models for accurately extracting medical information from structured and unstructured data sources  Work closely with product, UX, and clinical teams to prototype and test new functionality   Analyze performance results and convey your analyses to relevant stakeholders   Conduct research, publish and present your findings at relevant scientific venues   We lead with empathy for patients and our teammates  We value small egos, self-awareness, and humility in our teammates  We appreciate flexible and adaptive attitudes towards solving problems, as strategic priorities may shift  We love diversity of thought, perspective, working style, skill set, knowledge, and interests amongst our team  We value open dialogue and brainstorming across multidisciplinary teams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8-15 years of experience Strong exp. with SQL queries  Have some knowledge in Business intelligence tools SSIS, T-SQL Some Python experiences is plus ETL tools exp. is plus How to write complex sql queries - screen share  ETL modern stack - connecting data from APIs, jsons  Rewrite/modify Python code at minimum  Business intelligence resiliency team 40 data sources Helpful to have an understanding of the business -transform their requirements  Do reporting  Flexible on days - 3 per week\n",
      "Working on machine learning projects  Analyzing and processing data to create machine learning models  Implementing and optimizing machine learning algorithms  Testing and evaluating models  Collaborating with the programming team and other departments within the company to develop innovative solutions  Minimum 2 years of experience in the field of machine learning  Knowledge of machine learning algorithms and techniques  Ability to analyze and process data  Familiarity with machine learning tools and technologies  Proficient in English communication  Education in computer science  B2B contract type  Full-time employment  Remote and flexible working hours\n",
      " We are looking for a Data Science who is passionate about data and analysis tools, has the rigor needed to solve problems, and demonstrates curiosity and enthusiasm adopting new technologies to innovate.   The person will report to Senior Principal Data Scientist in HEOR-RWE and be focusing on building interactive applications on Amazon Web Services (AWS) Cloud, automating data pipeline, and facilitating training.   In your role as a Data Science temp, you will use AWS Cloud cutting-edge technology to design/manipulate heterogenous data sets, and build or enhance applications in the areas listed below:   Manipulate and merge data from different sources using programming language R or Python.   Create and improve efficiency of data pipelines on AWS Cloud.   Build data visualization dashboards and add features and functionalities using AWS QuickSight.   You will gain experiences working on healthcare clinical trials development industry, develop data driven solutions to increase clinical research efficiency.   You will be working closely with other members of our Data Science team to deliver value to our business partners.   Prefer a degree in data science, statistics, applied analytics, computer science, engineering, or a related discipline.   Curiosity and enthusiasm about data related techniques.   Exposure to AWS Cloud technologies.   Ability to program in Python, R or similar languages.   Proficiency in writing SQL queries to join tables and manipulate data.   Test and assess the quality of new tools.   Eager to learn a new set of tools in AWS Cloud and work on challenging problems.   Strong verbal and written communication and presentation skills.   Able to work with internal clients with minimal supervision.   Fluent written and spoken English   Hybrid\n",
      "ETL, analyzing Alteryx data Hands on Python Fixed Income Bonds SQL BI tools\n",
      "\n",
      " Conduct research to support ESG Risk analyses of opportunities  Assist in assessing the Scope 3.15 carbon footprint of the portfolio in alignment with the GHG Protocol  Attend Sustainability focused webinars and trainings, and summarize key learnings to share with the team.  Support development of communication materials (e.g., reports, slide decks) tailored to various audiences to describe and summarize results of research and data analysis.  Ability to implement scope 3.15 reporting  Knowledge of tools that support development of sustainability policy and strategy  Data analysis and visualization skills  Presentation and writing skills  GPA of 3.0 or higher  Undergraduate or graduate student pursuing an Economics, Finance, Business, Engineering, Science, Industrial Ecology or Policy degree with environmental or sustainability focus (e.g., Environmental Engineering or Science, Environmental Management or Policy)  Excellent communication, written, and organizational skills  Good data analysis skills and experience with Microsoft Excel and PowerPoint.  Ability to work independently with minimal supervision, and collaboratively in a team-focused group.  Works well in a geographically diverse team environment.  Knowledge of carbon footprint reporting methodologies  Fluency in Spanish\n",
      "Responsible for coordinating clinical research activities in accordance with ICH Good Clinical Practices, FDA guidelines, local regulations, and internal SOPs. As a contributing member on project teams, assist in the implementation of controlled clinical studies of client products. Manage the conduct of clinical studies in accordance with approved protocols and good clinical practices. Understand, read, and prepare technical documentation including, informed consents, study forms, and study training documents. Responsible for collecting and reviewing site regulatory documents.  Manage device accountability process. Conduct site initiation visits and closure visits at clinical study sites. Interface with monitors/CROs to address and resolve queries. Work closely with Project Manager(s) to ensure clinical studies are conducted in accordance with the protocol, GCP, SOPs, and all applicable regulations (e.g., FDA). Support budget and contract negotiations with clinical sites. Assist in writing clinical study reports by reviewing tables and listings generated from study data.  Bachelor’s degree in related field (Life Science degree preferred)  Minimum six (6) years of direct clinical research experience within the medical device industry  Clinical research expertise in various therapeutic areas (preferred areas: Neurovascular and/or Cardiovascular)  Knowledge of FDA regulations for clinical trials and clinical procedures  Experience using technologies for clinical research (electronic data capture and clinical trial management systems)  12-month contract, open to 12+ month extension 2 Video Interviews - Start 2 weeks from an offer Full-time, 40 hours/week Local to NJ/NY – must be able to travel to clinical sites locally  Benefits included (Medical, Dental, Vision, 401k)\n",
      "Build and architect data solutions in python with the intent to move into production.  Apply analytical methods to business problems utilizing data across disparate sources.  Create advanced data transformations and fixes to support analytical activities; write code optimized for cost, performance, and reproducibility.  Create reusable components and drives contributions to shared repositories; develop architectures to support production data science.  Deliver high quality project documentation and write compelling narratives to connect the business question/problem to the data, and the solution.  Serve as a resource for sign-off on code validation reviews.  Advanced programming ability in Python,  Advanced SQL capabilities for data extraction and analysis  Advanced dashboarding skill with Tableau (or AWS QuickSight)  Solid understanding of established design patterns  Solid experience in ETL development, data analysis, data visualization, and dashboarding  Strong communication and presentation skills with the ability to present technical\n",
      "Produces complex predictive models enabling the creation of rating plans and evaluation of risk and profitability. Identifies drivers of insurance costs, understanding the economics of customers’ behavior and estimating the expected losses for segments of risks using advanced statistical and analytical techniques on large data sets. Develops studies that evaluate new business models for customer retention and growth initiatives as well as estimate the lifetime value of customer segments. Participates in the development of the overall analytical framework to support the company’s strategy for growth Takes active role in innovation Mentors junior members of the team Communicates analysis, strategy and recommendations to diverse audiences, including technical and non-technical. Collaborates with upper management to assess the potential effects of proposed solutions and incorporates these considerations into recommendations. Advanced skills and training in predictive modeling, data mining and other quantitative and research analytics (Non-Linear Regression Analysis, Multivariate Analysis, Bayesian Methods, Generalized Linear Models, Decision Trees, Non Parametric estimations, etc.). Ability to apply various predictive modeling techniques to develop solutions to various real-world problems. Hands-on experience developing and delivering structured, methodology projects. Exceptional programming ability in SAS, SQL, R, Python or other programming languages. Excellent written and oral communication and presentation skills. In-depth understanding of database principles and experience working with large databases. Ability to influence and guide across departmental boundaries. 3 or more years of experience developing and implementing multivariate predictive models using GLM and other statistical methods. PhD in economics, statistics, or related field required. Or in the alternative, a Master’s degree in Statistics, Engineering, Mathematics, Economics, or a related field (foreign educational equivalent accepted) and five (5) years of experience as indicated above. High level of organizational and project management experience handling multiple projects simultaneously.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working with Clinical Data Management (CDM) in preparing eCRF requirement document, eCRF Completion Guideline, Integrated Data Review Plan, Data Quality Management plan and other study documents. Working with CDM in preparing UAT test scripts and participating systems UATs. Working with CDM in participating reports/dashboard QC/UAT Working with CDM in external data setup, and testing Working with CDM in data review activities including reviewing EDC queries and manual reports/listings. Currently enrolled in university, pursuing a Bachelor's in Computer Science, Engineering, Informatics, Biology, Chemistry, Pharmaceutical Sciences, Immunology or another related field. Have completed 2 yrs. Study in the above listed fields. Must be enrolled in university during the internship program. Deadline-driven with a high level of organizational and planning skills. Strong analytical, problem-solving, and oral and written communication skills. Ability to work well in teams, effectively manage projects, and present ideas clearly and concisely. Global mindset to grow in a diverse work environment. Excellent communication and leadership skills. Strong computer skills (MS Office). Database knowledge/experience will be a plus. Must be authorized to work in the US without sponsorship. Must be available to work Full time (40 hours/week), within core business hours (8 AM-5 PM), for a minimum of 10 weeks during the summer months.\n",
      "We are currently seeking a skilled Data Analyst with proficiency in Azure Data Factory (ADF), Databricks, Spark SQL, and dashboard creation. This role involves: Data Analysis with ADF and Databricks: Utilizing Azure Data Factory and Databricks for comprehensive data analysis. This includes extracting, transforming, and loading data (ETL) processes, and managing data workflows. Expertise in Spark SQL: Leveraging Spark SQL for querying and analysing large datasets within Databricks environments. The candidate should possess the ability to write efficient, complex SQL queries. Data Mapping Creation: Developing detailed data mappings to assist in the integration and transformation of data from various sources into structured formats for analysis. Dashboard Development: Designing and building intuitive, informative dashboards that effectively communicate data insights. Experience with tools like Tableau, Power BI, or Databricks’ native visualization capabilities is preferred. Data Quality and Integrity: Ensuring the accuracy and consistency of data throughout the data processing lifecycle, from extraction to visualization. Collaborative Project Involvement: Working collaboratively with cross-functional teams, including data engineers and business stakeholders, to understand requirements and deliver data-driven solutions. Data-Driven Decision Making: Assisting in the interpretation of data and providing insights that support business decision-making. Continuous Learning and Improvement: Staying updated with the latest trends and advancements in data analytics, ADF, Databricks, and Spark SQL to continuously improve processes and implementations. Technical Documentation: Creating clear and comprehensive documentation regarding data processes, mappings, and dashboard functionalities. Problem-Solving Skills: Utilizing strong analytical and problem-solving skills to address challenges in data analysis and dashboard development. The ideal candidate will have a strong background in data analysis, with a demonstrated ability to handle large datasets and build effective visualizations. They should be comfortable working in a dynamic, fast-paced environment and possess excellent communication skills to articulate complex data concepts to non-technical stakeholders.\n",
      "Regularly provides technical guidance and direction to support the business and its technical teams, contractors, and vendors Develops secure and high-quality production code, and reviews and debugs code written by others Drives decisions that influence the product design, application functionality, and technical operations and processes Serves as a function-wide subject matter expert in one or more areas of focus Actively contributes to the engineering community as an advocate of firmwide frameworks, tools, and practices of the Software Development Life Cycle Influences peers and project decision-makers to consider the use and application of leading-edge technologies Adds to the team culture of diversity, equity, inclusion, and respect Formal training or certification on software engineering concepts and 5+ years applied experience Exceptional skills working with databases, reporting engines, analytical tools. Solid understanding in one programming language e.g. Python, C/C++, Java etc. Exceptional skills in systems engineering and debugging.  Communicate with various partners e.g Business, Tech, Product and Quantitative research. Understanding of data science and financial engineering. Hands-on practical experience delivering system design, application development, testing, and operational stability. Advanced knowledge of software applications and technical processes with considerable in-depth knowledge in one or more technical disciplines (e.g., cloud, artificial intelligence, machine learning, mobile, etc.) Ability to tackle design and functionality problems independently with little to no oversight Practical cloud native experience Experience in Computer Science, Computer Engineering, Mathematics, or a related technical field Familiarity with cloud technologies Exposure in Database-related programming (both SQL and No-SQL) Familiarity with monitoring tools like Splunk, Elastic Search Knowledge of Credit Risk and Databricks\n",
      "Provide weekly, monthly, and annual reports for supply chain, trial balance and balance sheet Use Machine Learning in Python code within Power Platform to bring the cross-sell analytics, customer insights Build Canvas web apps using functional and logical expression in Power Apps Create custom connectors using API Prepare and deliver visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement Provide special reports and analyses to support the business as necessary using Power BI Support efforts to maintain accurate master data by curating the same using Power Query, SQL  Identify issues, analyze available data and information, and recommend changes to management  Create and maintain multiple operational reporting tools Consolidate data reports and deliverables to help drive data-based strategic decision making Provide analysis prior to and following any recommended changes.  Ensure accuracy of data through partnerships with team members Work cross-functionally with teams to drive data and reporting improvements. Master's in computer science/Applications, Information Technology/Systems and Math Sciences or Electronics/Electrical Engineering Minimum 6 months experience as Data Analyst, Business Intelligence Analyst, Data Engineer, Cloud Data Engineer or related Must be willing to travel/relocate to anywhere in the US What information we collect during our application and recruitment process and why we collect it; How we handle that information; and How to access and update that information.\n",
      "Working with Clinical Data Management (CDM) in preparing eCRF requirement document, eCRF Completion Guideline, Integrated Data Review Plan, Data Quality Management plan and other study documents. Working with CDM in preparing UAT test scripts and participating systems UATs. Working with CDM in participating reports/dashboard QC/UAT Working with CDM in external data setup, and testing Working with CDM in data review activities including reviewing EDC queries and manual reports/listings. Currently enrolled in university, pursuing a Bachelor's in Computer Science, Engineering, Informatics, Biology, Chemistry, Pharmaceutical Sciences, Immunology or another related field. Have completed 2 yrs. Study in the above listed fields. Must be enrolled in university during the internship program. Deadline-driven with a high level of organizational and planning skills. Strong analytical, problem-solving, and oral and written communication skills. Ability to work well in teams, effectively manage projects, and present ideas clearly and concisely. Global mindset to grow in a diverse work environment. Excellent communication and leadership skills. Strong computer skills (MS Office). Database knowledge/experience will be a plus. Must be authorized to work in the US without sponsorship. Must be available to work Full time (40 hours/week), within core business hours (8 AM-5 PM), for a minimum of 10 weeks during the summer months.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 6+ years of experience in IT. Skills in some of the following domains are essential with minimum 3-5 strong implementations and specific experience is desirable. Data Sciences and Machine Learning -experience in developing Client models like Supervised and Un Supervised learning with Neural Net, Deep Learning algorithms Language - Natural Language Processing, machine translation, language detection, classification with different aspects of dealing NLP like Phonology, Morphology Experience building complex classification and other prediction models using machine learning Linguistic Analysis - Different techniques of Syntax recognition, Semantics, Pragmatics with different approaches of Semantic analysis like Distributional, Frame based, Interactive learning et Thought Leader who can conceptualize big vision and define plan for Machine Learning, metrics and deliverables. Core Skills:  Technical - deep aptitude and proficiency in programming and design techniques Python and any distribution like Tensor Flow and knowledge into Java, Web/DB development, Big Data, complex event processing, design patterns. Understanding of technical architectures and current state of the market in several technology areas.\n",
      " Follow all policies and internal processes to ensure data programs and files are delivered in accordance with the provisions of the Health Insurance Portability and Accountability Act of 1996 and its implementing regulations, as amended (“HIPAA”).   Design, develop and validate data reporting solutions with minimum supervision.   Evaluate data and report findings for accuracy and completeness, per the data specifications.   Identify, investigate, and resolve data anomalies using SQL or other statistical analysis software. Escalate issues as needed per internal processes.   Responsible for monitoring file/data receipt, data implementation from different data sources for report generation per expected schedules. Identify/escalate/ resolve nonconformance .   Meet data reporting schedules to external stakeholders/ parties for designated data programs.   Seek and adopt best practices in data reporting, make recommendations for data processing improvements. Identify opportunities to improve the process and data accuracy.   Provide ad hoc data analysis to internal and external parties as requested.   Monitor and process weekly/monthly/quarterly reporting needs for different data programs.   Ensure that Asembia’s data reports meet program requirements and are delivered in a timely manner by making necessary changes to improve data accuracy.   Successful collaboration with other Asembia team members to attain a common goal.   Bachelor’s Degree required. B.A./B.S. Information Systems or similar field preferred.   Minimum 1 to 3 years of experience working in data analytics or Software Quality assurance – preference towards Prescription / pharmaceutical data.   Must have a working knowledge of SQL.   Must be detail oriented with the ability to focus on complex processing steps.   Nice to have advance level skills in developing solutions using SQL and SSIS.   Proven track record with taking ownership in data analytics or Software QA analysis. of data investigations, understand interdependencies within data and seeing them through to resolution, preferably using SQL.   Ability to evaluate insights from data analysis and suggest data process improvements.   Ability to manage multiple initiatives in a fast paced, dynamic team-based environment.   Strong self-starter with a sense of ownership.   Excellent organizational and collaboration skills. \n",
      "Establishes data infrastructure and scalable solutions to efficiently collect, organize, clean, verify, analyze, and visualize data from multiple data sources. Contribute to testing, quality assurance, and documentation of data pipelines and systems Provides data engineering and programming support to BD projects, including data visualization, data mining, data trending, and prediction based on large historical data for process, analytical and cell line development. Provides guidance, consultations, and training to BD scientists on data engineering and data science related topics. Promote digital-first mindset and data-driven decisions. Contributes to digital transformation, modeling and automation efforts across the Biologics Development organization Bachelor's degree in Data Science, Computer Science, Software Engineering, or relevant majors with significant training and experience in data engineering Required. Master's Degree Preferred In-depth knowledge of database architecture and design Proficient in programming languages such as Python, R, SQL, Java, or Scala and in debugging and diagnosing issues Expertise with data visualization tools such as Spotfire, Tableau, RShinyApp or Python Dash Experience with big data technologies such as Hadoop, Spark, or Hive is a plus A background in biologics development or pharmaceuticals is strongly preferred. Knowledge of electronic laboratory notebook systems and laboratory data management systems is highly desired. Demonstrated ability to understand business needs and clearly communicate technical concepts to audiences with diverse scientific backgrounds. Able to work independently or as a team member to meet goals, objectives, and commitments.\n",
      "Must have knowledge and experience with cGMP manufacturing, Quality, and compliance. Must have experience with Deviations, Root Cause Analysis, and CAPAs. Must have knowledge of data trending and tracking, including use of statistical analysis software a plus. Proficient in Excel data mining and report creation. Ability to use electronic Quality systems such as Infinity. Junior to intermediate ability to interpret results and situations and articulate recommendations for resolution. Knowledge of US and global cGMP requirements. Excellent verbal and written communication skills. Requires moderate direction to complete more complex tasks; completes routine tasks with little or no supervision. Work is self-directed. Confident in making decisions for non-routine issues. Able to prepare written communications and communicate problems to management with clarity and accuracy. Able to effectively multi-task. Associate degree or higher required, minimum of three years of experience in the pharmaceutical or related industry. Equivalent combination of education and experience acceptable. Responsible for trending of deviations at S12. Facilitates Trending Governance meetings. Issues minutes and notifies senior leadership of any risks or delays. Reviews all deviations and notifies management of any trends. Must have ability to author reports, interpret results, and generate conclusions consistent with Quality risk management principles. Knowledge of quality processes, including investigations, and CAPA management. Able to effectively multi-task.\n",
      "Develop and maintain robust code pipelines for textual data annotation, encompassing various levels such as lexicon-based and phrase-based annotation. Collaborate closely with cross-functional teams, including NLP researchers and software engineers, to integrate data annotation pipelines into the overall data processing framework. Design and implement data labeling rules based on lexicon groups using weak-supervision techniques, ensuring high- quality and consistent annotation outputs. Review and curate annotated data to maintain accuracy and relevance, addressing potential ambiguities and inconsistencies. Compute, analyze and present performance statistics, including precision, recall, F1 score, and other relevant metrics, to evaluate the effectiveness of the annotated pipelines. Collaborate with business stakeholders to understand their needs and goals, and translate technical findings to actionable insights that drive informed decision-making. Work closely with machine learning engineers to incorporate labeled data into model training and fine-tuning processes. Stay up-to-date with the latest advancements in NLP, data annotation techniques, and performance evaluation methodologies, and apply this knowledge to enhance annotation process. Document and communicate annotation pipelines, methodologies, and findings clearly to both technical and non-technical audience. Performing analysis to assess the quality and meaning of data. Build ETL pipelines and automate data ingestion, transformation and storage.  Master's in Computer Science, Data Science, Computational Linguistics, or a related field. Proven experience (5+ years) in NLP, data annotation and performance evaluation, preferably in an industry setting. Strong proficiency in programming languages such as Python and experience with relevant libraries (NLTK, spaCy, scikit-learn, etc.). Familiarity with developing and maintaining data pipelines, version control systems and continuous integration tools. Solid understanding of various NLP tasks, including sentiment analysis, entity recognition, text classification, etc. Experience with statistical analysis and visualization tools (e.g., pandas, matplotlib, seaborn) to present performance metrics. Excellent problem-solving skills, attention to detail, and ability to work on multiple projects simultaneously. Effective communication skills to convey complex technical concepts to both technical and non-technical stakeholders. Strong collaboration skills and ability to work with cross-functional teams. Knowledge of machine learning concepts and techniques is a plus. Experience with dashboarding tools like Power BI and Tableau. Attention to detail ensuring accuracy in data and recognizing anomalies or errors in data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lead initiatives to improve quality received from assigned suppliers  Support the qualification of parts and/or introduction of new suppliers  Manage supplier’s corrective action implementation through the Supplier Corrective Action process  Evaluate and disposition rejected material, as required  Use statistical analysis and risk management techniques to analyze quality data to identify trends and implement actions as needed  Provide guidance for process changes, including guidance on requirements for supplier and part’s qualification  Ability to travel to suppliers locations to address quality concerns  Lead/Participate on CAPA investigations, as required  Bachelor’s degree in Science or Engineering field of study  5-8 years of successful experience in medical device and quality engineering, and successful demonstration of responsibilities and knowledge as listed above  Incoming Inspection experience, preferred  Certified Quality Engineer (CQE), preferred  Certified Quality Auditor (CQA)/Lead Auditor Certification, preferred  Six Sigma Certification, preferred  Deep professional know-how and experience. Transfers and applies know-how to / in various contexts. Solid professional judgment and problem solving competence. Improves existing processes and approaches.\n",
      " Experience with SQL, Python, and git version control systems  Experience with cloud-based, distributed data systems, i.e., Snowflake, Spark  Experience with cloud computer systems i.e., AWS, AWS Glue, AWS Lambda  Experience with creating data visualizations to support communication of ideas  Experience in data pre-processing techniques for statistical and machine learning applications  Experience in the healthcare industry or with healthcare data  Experience with population-level analytics  Experience developing presentations to convey ideas (story telling)\n",
      "Works closely with others to gain strong understanding of insurance concepts such as financial P&Ls, expense ratios, rate level indications, loss ratio trends, and marketing funnel metrics and to get familiar with internal workflows (i.e. underwriting, sales and claims handling). Identify creative reporting solutions, including ad-hoc analysis that facilitates effective measurement of operational effectiveness. Upgrade existing reports to increase efficiency of distribution, reduce redundancy across reports and to improve ease of presentation.  Collaborate with other analytical teams throughout the enterprise to review insights from recent analytical exercises.  Effectively uses available front end reporting tools, data systems and information gathered from different areas throughout the company to analyze business issues. Communicate results to management.  Work with large databases from Production Data warehouse. Collaborate with data teams to leverage tools and techniques developed for effective data extraction, transformation and loading (ETL). Build automated reporting and analytical tools, which includes a) queries that extract and summarize data from our data warehouse and b) procedures that integrate this data into dynamic workbooks allowing for multiple levels of analysis. Acts as a liaison between the Business Intelligence team and other departments within the Direct Group. Demonstrated problem solving experience gained through related coursework and work experience. BA/BS degree in quantitative field of study. Property and Casualty Insurance experience preferred.  Analytical problem solver with a high level of intellectual curiosity and attention to detail. Prior Product or Actuarial experience desired.  Strong programming/query experience in SQL Server and Tableau report building. Proficient with all Microsoft Office products. Three or more years of experience with relational database tools and concepts.  Excellent verbal and written communication skills.  Collaborative nature, but also has the ability to work independently and efficiently on a high volume of tasks.\n",
      "Provide support to the Consultants teams by providing periodic benefits and cost analysis of our existing clients’ health and welfare plans with primary focus on medical, pharmacy, dental, life and disability on predominately Fully Insured Accounts. Maintenance of an assigned book of business  Perform financial analysis for all coverages, examining both overall cost and benefit structures, various plan design and contribution modeling on predominately Fully Insured accounts.  Develop budget forecasting followed by detailed recommendations and corrective action steps for existing Fully Insured Accounts clients. Ability to compare to a Fully Insured to a Self-funded model for comparative purposes with the guidance of the Data Team manager. Knowledge of the carrier claims reporting process as it relates to content and accuracy. Ability to manage both internal and external client deadlines by using the Data Project Request Tool. Ability to develop custom financial modelling at the client’s request and/or the ability to incorporate a “non standard “ request using our existing tools Attend client meetings/conference calls at the request of the Consultant.  Work with Data Team Manager and Consultant teams to analyze and negotiate Fully Insured rate renewals. Prepare recommendations and presentations to support the RFQ/RFP process for renewal business.  Provide support our cost modeling projects using the Data Analytics tools available including BeneFuture/Apex, Beneview and the various Data Warehouse utilities in place today. Identify process improvements when possible  Remain current on industry trends and information, new product information, legislation, regulatory requirements, coverage’s, compliance and technology; communicate changes and address issues with clients on a proactive basis.  Projects and assignments essential to the day to day operations of the employee benefits division as needed. Other duties as assigned.  Bachelor’s degree and/or equivalent business experience required. Minimum three to five (3-5) plus years’ experience working in the Broker/Consulting Analytics field; preferably in an underwriting and/or consulting role. Strong working knowledge in plan design, funding, underwriting, and related compliance issues impacting health and welfare plans. Experience in plan cost analysis, claim analysis and reconciliation and evaluation of financials.  Demonstrated knowledge of both self-insured and fully insured plans and both private and public sector clients. Strong written and verbal communication skills, presentation skills, critical thinking and problem solving skills.  Ability to make verbal in person presentations to internal staff and prospects/clients. Ability to work independently on projects and in a consultative team environment. Advanced proficiency in Microsoft Excel including financial modeling and underwriting analysis.  Proficiency in the Microsoft Office products including PowerPoint, Access and Word.  Authorized to work in the United States on a full-time basis without Company sponsorship.\n",
      "Should have 2-5 years of strong experience in analytics and data science. Expert in at least one programming language for data analysis (R required; Python is a plus). Demonstrated ability to develop R packages. Strong knowledge of SQL and relational databases. Experience with reporting and visualization solutions such as R Shiny, Tableau, or D3. Familiarity with reproducible research best practices. Ability to explain technical concepts and analyses clearly to a wide audience. Apply advanced statistical and machine learning techniques to translate the needs of the newsroom into reliable, valid models in order to Identify moments or subgroups of interest. Classify users or content. Highlight patterns, anomalies, relationships, and trends. Support long-term solutions and inform decision making. Wrangle constantly changing, large, complex, high volume, high dimensional, sparse data. Collaborate with business stakeholders and subject matter experts to ensure that developed solutions are practical and meet their needs in a timely fashion. Be a key resource for other data scientists through providing guidance on statistical methods and research design. Clearly communicate technical work to colleagues from across the Los Angeles Times, including non-technical colleagues. Qualifications Advanced degree (PhD preferred) in a quantitative or computing focused degree.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work with business teams to understand requirements, and translate them into technical needs Gather/organize large & complex data assets, and perform relevant analysis Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) Propose and implement relevant data models for each business case Create data models and optimize queries performance Communicate results and findings in a structured way Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements Leverage existing or create new \"standard data pipelines\" within the company to bring value through business use cases Ensure best practices in data manipulation are enforced end-to-end Actively contribute to Data governance community Remains up to date on company's standards, industry practices and emerging technologies Experience working with a variety of cross-functional teams Good understanding of agile/scrum development processes and concepts Able to work in a fast-paced, constantly evolving environment and manage multiple priorities Pragmatic and capable of solving complex issues Service-oriented, flexible team player Attention to detail & technical intuition Excellent written, verbal, and interpersonal skills for executive level communication and collaboration Fluent in English (Other languages a plus) Bachelor's Degree or equivalent in in Computer Science, Engineering, or relevant field Experience with AWS cloud services (Azure & GCP a plus) Good knowledge of SQL and relational databases technologies/concepts Experience working with data models and query tuning Experience in Data warehousing solutions (Snowflake a plus) Experience in Integration Services (IICS, Tibco a plus) Working knowledge of scripting languages (Python, R a plus) Familiarity with Source Code Management Tools (GitHub a plus) Familiarity with Visualization Tools (PowerBI, Tableau a plus) Familiarity with Project Management Tools (JIRA, Confluence a plus) Familiarity with Service Management Tools (Service Now a plus) Experience working in life sciences/pharmaceutical industry is a plus Relevant cloud certifications (AWS, Azure, Snowflake, IICS) are a plus Experience on working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements is a plus Mentoring and/or technology evangelism/advocacy experience Strong experience in automation tools and methodologies specifically using Gitlab, Github action, Terraform, Ansible Experience with programming languages such as Python, JSON, YAML, Shell Scripting Experience with backup system like Netbackup & CommVault Good knowledge of ServiceNow and monitoring tool such as Splunk, BPPM Experience with Real World Data (e,g, EHR, Claims) and standard data models (e,g, OMOP, FHIR) Experience using frameworks to create pipelines (e.g. Apache Airflow, Kedro)\n",
      "Develop and validate models. Design data engineering pipelines. Spearhead innovative projects. Create impactful visualizations. Collaborate with global teams. Contribute to team growth. Strong modeling skills. MS or PhD in relevant field. Proficiency in causal inference and longitudinal analysis. Fluency in English, SQL, and Python. Experience with AWS and Docker.\n",
      "Bachelor’s Degree in Computer Science, Information Systems, Business or related field or equivalent combination of education and experience  3+ years proven experience in large-scale software development  3+ years of data engineering experience  Consistent track record of delivering on commitments  Ability to define/design solution options, evaluate technical feasibility, and provide estimates on effort and risk  Awareness of associated KPIs and general metrics of customer success criteria.  Experience working with data sources such as Retailer POS systems, IRI, Nielsen, Panel data such as Numerator and Nielsen/IRI Panel.  Retail data experience – working with Walmart, Target, Amazon, Dollar General, Kroger..etc  Experience building positive relationships across teams and roles: business partners, product, engineering, architecture, and platforms  Ability to lead, influence and communicate effectively, both verbally and written, across teams and roles  Solid foundation in data structures, algorithms, and architecture patterns  Experience building distributed / cloud scalable, high-performance data solutions  Experience with batch processing frameworks such as Spark and Hive  Experience with messaging/streaming/complex event processing tooling and frameworks with an emphasis on Spark Streaming or Structured Streaming or Apache Nifi  Experience with data warehousing related concepts - e.g. SQL and SQL Analytical functions  Ability to learn new technologies, adapt quickly, and lead a team of highly capable engineers in solving complex problems  Experience participating in key business, architectural and technical decisions  Ability to identify and resolve both people and process related issues  Experience in Agile/Scrum application development  Familiarity with the principles of Domain Driven Design  Comfortability with a fast-paced, results oriented environment  Practical approach to solving sophisticated problems with ambiguous requirements    Experience programming in Python & SQL  Experience working in a public cloud environment, particularly Microsoft Azure  Experience building RESTful API’s to enable data consumption  Experience in developing Power BI dashboards using DAX, Power Automate flows, Web Applications  Experience with practices like Continuous Development, Continuous Integration and Automated Testing\n",
      "Work Hybrid schedule in Jersey City, NJ Headquarter's Offices 2-3 days per week. Use existing tools to review and analyze data contributed by insurance companies for trends, anomalies, emerging patterns, and data quality issues. Develop efficient ways to improve data quality and error detection processes within the scope of one or more lines of business. Work with our industry data partners to ensure the accuracy of our insurance-industry-experience database. Provide suggestions for improvements in data review procedures and proto-type targeted data marts for effective analysis and communication of data patterns. Collaborate with other ISO divisions (actuarial, analytical, and technology) to ensure widespread access to and understanding of our core data assets. Develop in-depth understanding of insurance coverages, actuarial methodologies, analytic models, and information quality control. Execute data engineering projects ranging from small to large either individually or as part of a project team Adopt an agile framework to schedule work, adjust as needed and continuously improve performance. Perform other duties as assigned.  Bachelor's degree in a STEM major or with STEM coursework learned in associated majors (Actuarial Science, Computer Science, Data Engineering, Data Science, Mathematics, Applied Mathematics, Statistics, Finance, Economics). A strong desire to drive societal change using data, technology, and analytics. Clear and concise communication skills, both verbal and written. Ability to work independently and as part of a team while managing several concurrent projects. Knowledge of MS Office and SQL is a MUST for day to day work. Experience with a general purpose (C++, JAVA) or analytical (R, Python) programming language is required. A self-starter with a commitment to innovation and pro-active problem solving that has demonstrated intellectual curiosity, creativity, and adaptability. Work/internship experience in property/casualty insurance preferred. Prior work/internship experience in a data-centric department. Knowledge of data management principles.\n",
      "Review project documentation before delivering to clients. Execute Quality System processes (CAPA, Deviations, audits, training, calibration, document control, records management) under the guidance of the Quality Manager. Identify and address QMS gaps and propose improvements. Maintain cGMP compliance following established SOPs. Foster open communication with colleagues. Assist in investigations and corrective actions. Support Data Integrity initiatives. Perform other duties as assigned. Preferably, a Bachelor of Science (BS) degree. Strong communication skills, both written and oral. Attention to detail and ability to multitask. Effective communication across the organization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead the delivery of commercial lines rating projects across lines of business, providing technical leadership to analytics direct reports and closely partnering with pricing actuaries on broader rating plan updates. Ensures technical excellence in rating delivery and alignment with business strategy. Instill appropriate combination of analytical expertise and subject matter expertise in refining rating plan structure. Consider internal and external data, competitor plans, internal product expertise and market signals in the pricing process. Leads and directs rating plan reviews across product portfolio. Implement actuarial rating plan standards, best practices, and guidelines. Develop appropriate governance of these standards (e.g., rating challenge/audit and peer review, compliance, and documentation, etc.). Work with actuarial line of business communities of practice to develop rating plan improvement strategies, including standard tools and platforms. Coordinate all rating externalization efforts, providing rating as a service to underwriting platforms. Instill continuous improvement culture for software and operational models for rating implementation, being knowledgeable of available platform, rating engine, and rules engine alternatives. Collaborate with various stakeholders including IT, Product Services, and Business Analysts to update, maintain, and document the implementation of our rating algorithms. Coordinate with IT on budget, requirements, and project prioritization. Work with business unit actuaries to provide documentation for actuarial rate filings as needed. BS Degree or higher in Mathematics, Actuarial Science, Statistics, Finance, or a related field. 10+ years of commercial lines actuarial technical pricing, modeling, and data science expertise with expert knowledge of an extensive range of commercial insurance products Credentialed actuary; FCAS preferred. Proficiency in Excel and other programming languages and tools, such as SQL / R / Python / FOCUS / RADAR along with a keenness for data (collection, manipulation, report design, sensibility checks, and attention to detail) and IT systems implementation. Experienced with usage of Git version control and implementing coding best practices. Prior managerial or supervisory experience with capability to develop team members for success and enforce accountability. Pro-active agent of change with excellent analytical and problem-solving skills. Strong organizational skills: ability to prioritize multiple competing deliverables and manage time effectively to meet scheduled due dates. Strong collaboration skills: ability to work closely with other disciplines and influence outcomes. Excellent interpersonal and communication skills; ability to provide clear and concise verbal and written communications regarding analyses and observations to non-actuarial business partners and leaders. Desire to work in a fast-paced, fluid environment.\n",
      "Assist engineers and developers to add value to Own products with data analytics and problem prediction Conduct research on ways to provide customers with insights into their data  Develop and validate processes to evaluate data analytics and ML performance and effectiveness Document data science and ML methods and results in ways that are understandable to engineers and customers. Assist UX team members integrate data visualizations into Own products Current enrollment in a bachelor's degree program in a statistics-related field, including data science, mathematics, or a concentration in statistical techniques Strong written and verbal communication skills Proficiency with programming in Python and/or R. Experience should include working with dataframes, text analysis, text search using regex, and visualization tools using languages like Python or R. Javascript, C, C++ desired Microsoft Office Suite  Basic knowledge of using databases and analytics engines, including SQL-like relational databases and Spark and associated tools is a plus Familiarity with data visualization methods such as tree maps, heat maps, stream maps Strong research and problem-solving abilities Highly organized, detail-oriented, and able to manage multiple tasks simultaneously. General experience with data cleaning and exploratory analysis, requirements analysis, and detailed reports Eagerness to learn and contribute in a fast-paced environment Opportunity to gain hands-on experience developing and implementing data science and machine learning methods in real world applications Exposure to day-to-day operations Mentorship and guidance from experienced professionals Networking opportunities within the organization\n",
      "During this internship, you will investigate essential hybrid large language models (LLM) and knowledge graph algorithms designed for static and time-series data. The aim is to create step-by-step instructions that can assist industry 4.0 service engineers in resolving technical issues for customers. The project will specifically center on modeling and prototyping new techniques, employing the latest approaches to large language model (LLM)-based knowledge extraction from unstructured data, encompassing documents, text, and images. You will investigate and apply algorithms such as deep neural networks in the shape of natural language processing (NLP) transformers, knowledge model-building techniques like graph embeddings, automatic topic modeling, unsupervised clustering methods, and hybrid neural-symbolic learning methods.  Knowledge of machine learning and/or natural language processing, such as large language models (LLMs) and their application to real-world problems.  Affinity with building web applications and loves to code in Python and/or Java/JavaScript. Strong ability to work within teams with excellent interpersonal skills and written/verbal communication skills. Some experience with creating practical data analytics and/or machine learning applications. Disclaimer: Benefits do not apply to student, intern, or Co-op positions. Specific terms and conditions for internships and co-op programs will be outlined separately.  One of the World’s Most Ethical Companies by Ethisphere   Gender-Equality Index by Bloomberg   Workplace Pride Global Benchmark  Pension Plan - Cash Account Program Medical and dental coverage Short term disability and long-term disability Life insurance and AD&D – Company paid 2 x base pay Supplemental life and AD&D insurance (Employee/Spouse/Child) Health care and dependent care Flexible Spending Accounts Pre-tax commuter and parking benefits Savings/401(k) Plan Paid time off for holidays and vacation Employee Stock Purchase Plan Tuition Assistance Plan Adoption assistance Employee Assistance Program/Work Life Resource Program Voluntary benefits including vision, legal, auto & home Insurance, pet insurance, Identity Theft Protection Services, and Health Advisory Services” Nokia Perks At Work\n",
      "Data Analysis as assigned. Perform different levels of problem resolution & data analysis for all aspects of retirement operations support including: contributions, distributions, processing conversions, recharacterizations, and state withholding reconciliation. Reconcile activities to ensure transactions are recorded with the proper books and entry coding. Assist the management team in developing metrics that demonstrate the progress / completion of retirement inquiry resolution. Execute on customer requests to move money out of retirement accounts. Understand tax implications of transactions in and out of different retirement account types. Resolve retirement account issues and document the resolution process. Deliver objective analysis of error trends and opportunities. Validate data integrity is maintained in client facing displays. Quality Assurance. Support strategic plans that enhance productivity through process efficiencies and automation. Follow established procedures and quality assurance for retirement processes. Develop and lead account reconciliation efforts. 3-5 years of experience with retirement account operations, IRS rules, and/or tax reporting obligations. Analytical thinker, with excellent written and verbal communication. Detail oriented with strong organizational skills. Ability to manage multiple projects, prioritize tasks, and work against multiple deadlines and objectives.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborate with stakeholders to gather and prioritize business requirements. Write comprehensive and detailed functional business requirements. Tell compelling stories with data, providing actionable recommendations based on your analysis. Understand data connections from the front end to back end systems. Utilize your ability to speak and present well to facilitate communication between business stakeholders and the IT team. Conduct meetings, workshops, and presentations to gather information and share insights effectively. Collaborate with UX teams to enhance the overall user experience of the solutions. Must have experience gathering and documenting business requirements Experience writing user stories Must have excellent verbal and written communication skills with the ability to speak and present effectively Background in user experience to contribute to user-centric solutions. Must have strong analytical thinking and the ability to tell a story with data Must have understanding of data integration Must have Salesforce experience  Health Cloud experience preferred  Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. Flexible work Healthcare including dental, vision, mental health, and well-being programs Financial well-being programs such as 401(k) (matched 150% up to 6%) and Employee Share Ownership Plan 100% Company-paid mobile phone plan 3 weeks Personal Time Off (PTO) and 7 Paid Holidays Paid parental leave Family building benefits like adoption assistance, surrogacy, and cryopreservation Social well-being benefits like subsidized back-up child/elder care and tutoring Mentoring, coaching and learning programs Continuing Education: $12,000 Annual Tuition Reimbursement plus access to over 20,000 online courses and certifications through Capgemini University, as well as Coursera and Degreed. Programs for Counseling, Support, Health and Fitness perks, Auto discounts and much, much more! Employee Resource Groups Disaster Relief Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.\n",
      "Design and implement QSPR and ML models for the reliable prediction of optoelectronic properties. Design and implement generative ML models for the creation of superior optoelectronic materials. Continually improve the models being used for molecular design and property prediction. Collaborate with members of the Modeling and Simulation team to leverage the latest developments in quantum mechanical and forcefield simulation. Work integrally with members of the Synthetic Chemistry team to identify and optimize promising leads in a fast-paced and dynamic environment. PhD in Chemistry, Physics, or Computer science. Fundamental understanding of data analysis. Prior experience with ML and its application to molecular design. Familiarity with approaches such as recursive partitioning, decision trees, supervised learning, unsupervised learning, and generative models. Experience with deep learning frameworks such as PyTorch or TensorFlow. 2+ years Post-doctoral experience. Expertise with Python, Java, SQL Prior experience with small molecule organic and/or organometallic chemistry. Competitive base salary and annual bonus program Medical/Prescription Drug coverage, Dental, and Vision for employees and family Transit, Health and Dependent Care Flexible Spending Accounts (FSAs) Health Reimbursement Account (HRA) – An employer-paid benefit to reimburse a portion of employees’ eligible out-of-pocket medical expenses, such as deductibles, coinsurance, and pharmacy expenses Group Term Life insurance, short term disability, and long term disability benefits for employees Employee Stock Purchase Plan (ESPP) 401(k) company contribution Ewing Worldwide Headquarters (HQ) cafeteria provides breakfast and lunch to employees at no cost to them Annual charitable matching gift Generous Paid Time Off\n",
      "Lead the delivery of commercial lines rating projects across lines of business, providing technical leadership to analytics direct reports and closely partnering with pricing actuaries on broader rating plan updates. Ensures technical excellence in rating delivery and alignment with business strategy. Instill appropriate combination of analytical expertise and subject matter expertise in refining rating plan structure. Consider internal and external data, competitor plans, internal product expertise and market signals in the pricing process. Leads and directs rating plan reviews across product portfolio. Implement actuarial rating plan standards, best practices, and guidelines. Develop appropriate governance of these standards (e.g., rating challenge/audit and peer review, compliance, and documentation, etc.). Work with actuarial line of business communities of practice to develop rating plan improvement strategies, including standard tools and platforms. Coordinate all rating externalization efforts, providing rating as a service to underwriting platforms. Instill continuous improvement culture for software and operational models for rating implementation, being knowledgeable of available platform, rating engine, and rules engine alternatives. Collaborate with various stakeholders including IT, Product Services, and Business Analysts to update, maintain, and document the implementation of our rating algorithms. Coordinate with IT on budget, requirements, and project prioritization. Work with business unit actuaries to provide documentation for actuarial rate filings as needed. BS Degree or higher in Mathematics, Actuarial Science, Statistics, Finance, or a related field. 10+ years of commercial lines actuarial technical pricing, modeling, and data science expertise with expert knowledge of an extensive range of commercial insurance products Credentialed actuary; FCAS preferred. Proficiency in Excel and other programming languages and tools, such as SQL / R / Python / FOCUS / RADAR along with a keenness for data (collection, manipulation, report design, sensibility checks, and attention to detail) and IT systems implementation. Experienced with usage of Git version control and implementing coding best practices. Prior managerial or supervisory experience with capability to develop team members for success and enforce accountability. Pro-active agent of change with excellent analytical and problem-solving skills. Strong organizational skills: ability to prioritize multiple competing deliverables and manage time effectively to meet scheduled due dates. Strong collaboration skills: ability to work closely with other disciplines and influence outcomes. Excellent interpersonal and communication skills; ability to provide clear and concise verbal and written communications regarding analyses and observations to non-actuarial business partners and leaders. Desire to work in a fast-paced, fluid environment.\n",
      "Do they have a minimum of 5 years of IT experience? Do they have experience with Tableau reporting? Experience with Alteryx? Experience with Marketo?\n",
      "Manage market research projects for in-line and pipeline brands for US and/or Canada launch, including message testing, payer/pricing research, physician ATUs, patient ATUs, physician segmentation, patient segmentation, demand research, and patient journey research.  Conduct data analysis and generate insight on launched products to report on performance and guide management and the field. Contribute insights to launch strategies and overall commercialization efforts on in-line and pipeline brands to meet or exceed launch plan objectives. Provide pipeline and in-line product forecasts.  Contribute and/or run projects related to competitive landscape, and possibly sales force sizing, sales force IC design, and ROI analyses of sales and marketing efforts.  Conduct other analysis as needed. Rare disease and CNS experience is a plus.  Manage vendors with an eye towards bottom-line Mitsubishi Tanabe Pharma America profitability. Impeccable professionalism, communication skills, organization skills, and ability to manage multiple projects and priorities simultaneously and to adhere to tight timelines and ensure deadlines are met with high quality output.  Work with cross functional teams (Marketing, Sales, Market Access, Finance, Medical Affairs, Clinical, and Regulatory) to create effective, positive partnerships with peers and key internal/ external stakeholders and ensure alignment of business needs and objectives.  Bachelor's degree required. Master’s preferred  Minimum of 5 years of experience, with strong knowledge of pharmaceutical industry commercial analytics and market research, preferably with 3-5 years in a role with market research, data analysis, modeling, and competitive monitoring.  Knowledge of market research methods and practices.  Experience with pharmaceutical industry launches, preferably with dynamics related to rare diseases and the Neurology/CNS market. Experience with IQVIA and other industry-standard data.  Leads by example, displaying integrity, collaboration, accessibility, adaptability, sound judgment/decision making, and an entrepreneurial, solutions-oriented attitude. Demonstrates responsiveness, attention to detail, and follow-through coupled with ability to prioritize/multi-task effectively. The ability to synthesize complex information, distill critical insights to inform commercial strategies, and then translate to tactical level. Excellent written/verbal communication and presentation skills. Highly proficient in MS Office; skilled at and interested in developing pharmaceutical product forecast models and quantitative analyses. Working knowledge and understanding of the Pharma industry, broad therapeutic areas/disease states, drugs/treatments, and related regulatory, commercialization and compliance requirements. Must be able to travel 20% domestically and internationally for business and project meetings as require.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will manage large-scale actuary and risk projects across internal and external vendor spend, casualty and life insurance You will report directly into the Chief Data Scientist and work closely on technical and strategic direction You will oversee implementation and design of ML and statistical code and build out to production with access to petabytes of data Work across the commercial side of the business Partner extensively with internal business leaders Scale out and manage a brand new DS team Experience leading large-scale projects which directly impact business direction across actuary, risk and finance Background building statistical applications in financial services and/or insurance Fluent in communicating with nontechnical stakeholders across business departments and in the C-suite Prior experience leading business-critical projects aimed at mitigating business risk Large-scale team management experience required PhD/MS in Statistics, Economics, Applied Mathematics, Actuarial Science or Computer Science Machine Learning expertise required\n",
      "Engage with clients, create a need for data solutions, and drive solution development. Translate client requirements for an offshore team, managing front-end processes. Collaborate on the creation of dashboards, applications, and presentations. Determine requirements across data solutions, visualizations, and application design. Play a sales-oriented role, influencing key accounts and fostering client relationships. Collaborate with the offshore team to execute end-to-end data solutions. Manage a team of 8 individuals (2 onshore, 6 offshore) working on data projects. Grow key accounts through effective solution delivery and client management. 5-8 years of enterprise level experience as a Data Consultant, ideally within the pharma/met-tech space Proficiency across Power BI and analyst suite tools Technical leaning, ideally specialized in Azure Project Management experience is also a plus\n",
      "Hybrid to remote 3 days on site Data Science Temp – HEOR-RWE, BD Be part of something bigger! BD is one of the largest global medical technology companies in the world and is advancing the world of health by improving medical discovery, diagnostics and the delivery of care. We have over 65,000 employees and a presence in virtually every country around the world to address some of the most challenging global health issues. In today’s fast evolving medical technology world, one aspect remains common – reliance on data to drive the next wave of innovation. The Data Scientist in HEOR-RWE will help advance BD’s Real-World Evidence (RWE) strategy and help build the right analytics strategy for a range of Business Units and Functions. We are looking for a Data Science temp who is passionate about data and analysis tools, has the rigor needed to solve problems, and demonstrates curiosity and enthusiasm adopting new technologies to innovate. The person will report to Senior Principal Data Scientist in HEOR-RWE and be focusing on building interactive applications on Amazon Web Services (AWS) Cloud, automating data pipeline, and facilitating training. In your role as a Data Science temp, you will use AWS Cloud cutting-edge technology to design/manipulate heterogenous data sets, and build or enhance applications in the areas listed below: Manipulate and merge data from different sources using programming language R or Python. Create and improve efficiency of data pipelines on AWS Cloud. Build data visualization dashboards and add features and functionalities using AWS QuickSight. You will gain experiences working on healthcare clinical trials development industry, develop data driven solutions to increase clinical research efficiency. You will be working closely with other members of our Data Science team to deliver value to our business partners. Prefer a degree in data science, statistics, applied analytics, computer science, engineering, or a related discipline. Curiosity and enthusiasm about data related techniques. Exposure to AWS Cloud technologies. Ability to program in Python, R or similar languages. Proficiency in writing SQL queries to join tables and manipulate data. Test and assess the quality of new tools. Eager to learn a new set of tools in AWS Cloud and work on challenging problems. Strong verbal and written communication and presentation skills. Able to work with internal clients with minimal supervision.\n",
      "Set up and maintain KDF equipment for preparing experiments and coating jobs Provide technical support and troubleshooting for KDF products as required Lead a team of support people to set up, run, and train customers on KDF equipment in the field Resolve product support and customer process problems as necessary Resolving product support and customer process problems as necessary Motivated and self-directed (90% of time) Keep detailed notes on experiments and tests and save the test results digitally Interact and work effectively with customers and KDF personnel to solve PVD (physical vapor deposition) process issues Will conduct experimental techniques from forming concepts and building test stands as well as running experiments, analyzing data and generating test reports Follow company policies and procedures Other duties as assigned B.S. degree in Science or Engineering At least 2 years of experience  Working knowledge of Vacuum Technology and Physical Vapor Deposition (PVD) techniques like sputtering Working knowledge of in-house thin film metrology tools (profilometer, ellipsometer, reflectometer, RGA, etc.) Proficient in running experiments, analyzing data and generating test reports Strong problem solving, communication, interpersonal and project management skills Ability to work in an organized and efficient manner Ability to work safely around high voltage equipment English Language skills Proficient with MS Office suite Ability to travel domestically and internationally Ability to bend, stoop, squat, twist and lift up to and including 30 lbs. unassisted. Assistance must be used for any items over this weight. Assistance is always required for anything weighing over 60 lbs Company paid medical and dental insurance 401k plan Paid vacations Sick time Salary is dependent based on experience.\n",
      "This role is involved in conducting Lab studies. The studies involve blood. Should be comfortable working with blood. Should be able to independently execute studies. Need to have great lab skills, experience with data analysis, write reports & study protocols. Need to have wet lab skills such as pipetting and experience with in vitro studies. Day to day involves designing studies and attending team meetings, writing protocols, executing testing in the lab, doing data analysis and providing final reports. Generally, data analysis is done in Excel or Minitab, GraphPad. Experience doing data analysis in Excel or Minitab or GraphPad is a big plus. B.S./M.S. with minimum 2 years industry experience or a fresh Ph.D. (contingent on the Ph.D. being lab based). PhD should be from a related wet lab. Degree in Biomedical engineering or Biology is preferred. But if the candidate has a related degree but has worked in a biology lab with wet lab experience, they would be considered as well.\n",
      "Be the face of our Generative AI capabilities for clients in Life Sciences domain. Proactively work with Client Partners to grow Generative AI footprint in our clients and position as a leading solution provider in this space. Actively search for opportunities to expand business within existing accounts and help win new clients. Proactively develop differentiated Generative AI solutions & Service Offerings for Life Sciences domain and leverage similar solutions from other Verticals. Identify, assess, and develop Generative AI and AI/ML applications by applying key industry tools, techniques, and methodologies. Experience in Life Sciences (Pharma + MedTech) domain Building new technology capabilities, and building team competencies Manage business relationship with the technology partners & start-up eco systems and demonstrate edge over competition. Passionate about technology and customer success with excellent communication and articulation skills Ability to communicate technical concepts and solutions at a level appropriate for technical and non-technical audiences. Research, curate, and record tutorials on various applications of data science and machine learning, especially on Generative AI Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects. Consulting and Advisory focus with ability to interact with and present to senior and mid-level client stakeholders. Strong analytical, creative, problem-solving, and critical thinking skills  Detail-oriented team player who can consistently provide valuable suggestions and solutions in areas of analytical solutions. Leadership skills and Can-do attitude to ensure that high quality solutions are being developed by diverse teams. Strong verbal and written communication as well as interpersonal skills Conceptual thinking to ensure all parts of an application function together as intended. Bachelor’s or master’s Degree Proven experience as an Enterprise Architect, Solution Architect, or a similar role, with a focus on AI/ML and generative AI. Strong understanding of generative AI techniques, including deep generative models, autoregressive models, and reinforcement learning for generative tasks. Hands-on experience of machine learning methodologies including advanced analytics tools (such as R and Python) along with applied mathematics, ML and Deep Learning frameworks and libraries (TensorFlow, PyTorch, Keras) and ML techniques. At least 5+ years of hands-on experience with building language models, machine learning and AI models leveraging industry tools, products, and / or Azure cognitive services. Deep and hands-on expertise in (as an individual contributor) Undertaking data collection, Data mining, preprocessing and analysis of structured and unstructured data. Hands-on expertise in large language models (LLMs/LSTMs/BERT) that can perform complex reasoning in few- and zero-shot settings by generating intermediate chain of thought (CoT) reasoning steps Experience of building / customizing and fine-tuning AI models including LLM models via OpenAI (Azure), Bert (AWS) for rapid PoCs Experience on LLM Model Governance, LLMSecOps, Hallucination and bias handling Deep and hands-on experience in applying machine learning algorithms. Strong data science and data engineering background both with open source and cloud distributed machines learning and AI tools especially Azure Cognitive Services, Azure Machine Learning and AWS Sagemaker and Bedrocks Strong understanding of Azure cloud technology including Cognitive Services viz. Vision, Speech, Language, Decision, Search and GenAI and its implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position: Data Engineer Client: Broadridge Financial Solutions Location: Newark, NJ Hybrid: 2-3 days onsite if local – can be 100% remote Snowflake Expertise: AWS Proficiency: Airflow Workflow Orchestration: Architecture Design: Languages. Qualifications:\n",
      "4-6+ years of professional work experience designing and implementing data pipelines in a cloud environment is required. 4+ years of experience migrating/developing data solutions in the AWS cloud is required. 2+ years of experience building/implementing data pipelines using Databricks or similar cloud database. Expert level knowledge of using SQL to write complex, highly optimized queries across large volumes of data. Hands-on object-oriented programming experience using Python is required. Professional work experience building real-time data streams using Spark and Experience in Spark. Knowledge or experience in architectural best practices in building data lakes\n",
      "Collaborate with cross-functional teams to design and implement statistical methodologies for clinical trials, including sample size determination, randomization schemes, and statistical analysis plans Analyze and interpret data using appropriate statistical techniques, ensuring the accuracy, validity, and reliability of results Develop and validate statistical models to support clinical study endpoints including regression analysis, and longitudinal data analysis Provide statistical input in the development and review of study protocols, method validations, and other study-related documents Generate statistical analysis reports, presenting findings to internal and external stakeholders in a clear and concise manner Contribute to the continuous improvement of statistical practices within the organization by staying current with advances in biostatistics methodologies Collaborate with researchers to ensure compliance with regulatory requirements and industry standards Master's degree in Biostatistics, Statistics, or a related field At least 5 years demonstrated experience using statistical software such as SAS, R, or Python At least 3 years working with statistics and data to generate a variety of results Proven experience in applying statistical methods in a clinical research setting, preferably within the pharmaceutical or biotechnology industries Solid understanding of clinical trial design, protocols, and regulatory requirements Possess strong analytical skills with the ability to solve complex problems and make sound decisions based on statistical analysis\n",
      "Utilize statistical predictive models, including regression and time series models, to identify trends, make accurate forecasts, and generate projected figures. Leverage machine learning techniques, such as classification, collaborative filtering, association rules, sentiment analysis, and topic modeling, to gain insights from natural language data. Create new dashboards and self-serve capabilities that empower the field force, providing data-driven insights to leaders for sales optimization and performance management. Drive initiatives focused on big data and advanced business analytics across diverse domains, such as product sales and marketing research. Communicate findings effectively through reports and presentations to educate others. Knowledge of master data management and governance concepts and process improvement disciplines Data quality measurement and monitoring, including definition of business rules, technical data quality rules, metrics and exceptions management and understanding of Data Governance best practices Develop and maintain data architecture documentation Develop and maintain information flow and data interchange requirements Drive data architecture decisions on data, analytic and reporting intiatives Continuously monitor and optimize the size and structure of the field team. Lead and manage the incentive compensation program for the sales organization. Work with Sr Manager, Data & Analytics position to link CRM and analytics tools, ensuring their effective utilization and maximum benefit. University degree (B.A. /B.S.) required, life science, informatics, and/or healthcare management preferred. Master’s degree a plus 8+ years Pharma / Biotech experience, or equivalent in Life Sciences Consulting. Hematology/oncology knowledge, experience in the field of allogeneic transplantation and/or cellular therapies (CAR T), preferred Experience with Machine Learning, Artificial Intelligence, or other programming languages is highly desired. Experience working with remote field based employees Proven track record in working across relevant stakeholders(s), e.g. medical, sales, marketing and/or account management Developer/Administrator of Power BI Strategic and analytical thinker, with a well-balanced medical/science, technical and commercial mindset Strong communication and negotiation skills (verbal/written), ability to build and maintain reliable internal customer relationships Skilled team player, with collaborative mindset and proven experience in team coordination and/or cross-functional leadership Extensive knowledge of U.S. healthcare environment, applicable laws, regulations and standards preferred Agile learner with the ability to work effectively in complex, rapidly changing environments and to prioritize activities effectively Strong analytical capabilities with emphasis on statistics/quantitative analytics Health Insurance Dental Insurance Vision Insurance Life Insurance Matched 401K Flexible Spending Account Health Savings Account AD&D Insurance Short-Term Disability Long-Term Disability Paid Maternity Leave Paid Paternity Leave Pet Insurance Critical Illness Insurance Hospital Indemnity Insurance Accident Insurance Legal Insurance Commuter Benefits Employee Assistance Program\n",
      "ML Engineer with 5-7 years of IT experience Pipeline Training Models, Building, Deployment, Testing, and Monitoring using AWS SageMaker, AWS CFT, AWS CodePipeline, Lambda, etc Develop Airflow DAGs to run training and scoring pipelines Develop a Testing framework with Pytest  Implement monitoring solution with homebrew solution using Lambda and Dash  Develop Data Quality solutions potentially leveraging Great Expectations Bachelor's degree or higher in computer science or related, with 5+ years of work experience Ability to collaborate with Data Engineers and Data Scientists to build data and model pipelines and help run machine learning tests and experiments Experience in AWS - SageMaker (ProcessingJobs, TrainingModels, EndPoints) Experience in Lambda CloudFormation or Terraform Apache Airflow, Astronomer Docker  Knowledge of traditional ML Models Python, Spark, Hadoop, and Docker with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design Knowledge of ML frameworks like Scikitlearn, Tensorflow, and Keras Experience in Pandas, sklearn, Numpy, Scipy Knowledge of Database/Data Engineering Experience with Oracle, Spark, Hadoop, Athena, API, FastAPI, Flask, ReST Knowledge of MLflow, Airflow, and Kubernetes Experience with Cloud environments and knowledge of AWS Services, Service Catalog, SNS, SES\n",
      "Assist in collecting and analyzing sales and marketing data from various sources  Contribute to the development of comprehensive reports and dashboards  Collaborate with cross-functional teams to plan and execute targeted email marketing campaigns  Support the management of the CRM (Salesforce)  Learn to translate complex data into actionable insights for the executive team  Participate in A/B testing and data-driven approaches to optimize campaign performance  Contribute to market research, competitive analysis, and identification of trends  Collaborate with global teams to align on reporting goals  Learn to ensure data accuracy, integrity, and security through data governance practices  Stay informed about industry trends and advancements in marketing analytics  Currently pursuing a degree in Marketing, Business, Analytics, Data Science, Economics, Mathematics or a related field.  Strong analytical skills with an eagerness to interpret data and identify trends  Interest in marketing automation platforms, CRM systems, and email marketing tools  Detail-oriented with a focus on accuracy and quality in data management  Strong written and verbal communication skills  Ability to adapt to a fast-paced environment and work effectively under tight deadlines  Knowledge of Salesforce, Google Sheets/Microsoft Excel, Keynote, SQL, Tableau, or other BI tools is a plus  Opportunity to gain hands-on experience in the Saas Sales Industry, Data Analysis, and Revenue Operations  Exposure to day-to-day operations, new technologies, and knowledge of sales processes  Mentorship and guidance from experienced professionals  Networking opportunities within the organization \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Develop and deploy real-time multivariate monitoring models using statistical software to support the technology transfer and manufacturing of advanced therapies processes. Identify, develop and implement process improvement initiatives. Apply creative solutions to various data science projects. Provide technical support to process investigations. Create predictive models to help achieve optimal process performance. MS / BS in an engineering discipline (biomedical, chemical, biochemical, biostatistics etc.), or any life science equivalent in computational sciences Knowledge and experience in data analyses, visualization and report writing is required. Experience using either R or python; and git version control; and/or other statistical software. Knowledge of statistics and analyses (e.g. ANOVA, T-tests, Regression, Control Charts) Experience with pharmaceutical drug substance & drug product manufacturing processes is a plus. Excellent communication skills, both oral and written Team player: working in cross-functional teams.\n",
      "Model Development: Collaborate with the research and development team to understand project requirements and formulate deep learning solutions. Design, train, and optimize deep learning models for various applications. Data Preprocessing: Prepare and preprocess large datasets for model training and validation. Ensure data quality and integrity to achieve accurate and reliable model predictions. Environment Setup: Set up and maintain deep learning environments using frameworks like TensorFlow, PyTorch, or Keras. Utilize cloud-based platforms such as AWS, GCP, or Azure for scalability and efficiency. Model Training and Evaluation: Conduct experiments to train deep learning models and evaluate their performance using appropriate metrics. Fine-tune models to improve accuracy and efficiency. Deployment and Integration: Collaborate with software engineers to deploy deep learning models into production environments and integrate them with existing systems. Research and Innovation: Stay up-to-date with the latest advancements in deep learning research and apply cutting-edge techniques to improve our models and products. Documentation and Communication: Document your work thoroughly, including model architectures, training methodologies, and results. Present findings and progress to the team and stakeholders in a clear and concise manner. Bachelor's or Master's degree in Computer Science, Engineering, Mathematics, or a related field. Solid understanding of deep learning algorithms and frameworks (e.g., TensorFlow, PyTorch, Keras). Proficiency in Python and its data science libraries (e.g., NumPy, Pandas). Experience with cloud-based platforms for model development and deployment (e.g., AWS, GCP, Azure). Familiarity with data preprocessing techniques and tools. Strong problem-solving skills and the ability to work effectively in a team environment. Excellent communication skills and the ability to explain complex concepts to non-technical stakeholders. Previous experience in deep learning projects, such as computer vision or natural language processing. Knowledge of GPU acceleration for deep learning training (e.g., CUDA). Familiarity with version control systems like Git. Understanding of big data technologies, such as Hadoop or Spark.\n",
      "Perform User Acceptance Testing of the Functional Requirements of the payment system, filtering system and other systems used by the PCS team. Create Business Requirement Documents on system enhancements. Support in the UAT governance for major releases : UAT Test Plans, UAT Test Scenarios, Test Cases, Test Scripts, and traceability matrix. Work closely with the testers and SME’s to coordinate all testing needs (environments, reports, partner systems). Support the team with project management, system migrations, enhancements, and bug fixes. Ensure adherence to all external regulatory and internal policy guidelines as dictated by the position. Must Have: UAT OR USER ACCEPTANCE TESTING AND AHC OR SWIFT OR WIRE OR AUTOMATED CLEARING HOUSE. 3 -5 years of relevant experience with a focus around IT analysis and testing. Bachelor’s degree in Data Analytics, Information Technology and/or Computer Science. Previous relevant experience in a banking application testing environment, preferable payment applications. Test preparation and execution experience. Strong problem solving and good analytical skills (defect analysis and reporting). Strong attention to detail. Ability to interpret large set of data and draw patterns using tools preferably advance MS excel. Track record of successful project completion working in a team. Good knowledge of software development lifecycle and defect resolution processes in particular. Ability to multi-task and test different applications relating to a release. Good time management skills and the ability to work to tight deadlines. 3-5 years of UAT experience. 1-3 Years of  experience in corporate banking environment. Test Preparation and Execution experience. Extensive knowledge of MS Excel & MS Word. Proficiency with reporting tools Business Object & Tableau dashboard. Basic knowledge of database (SQL). Expertise in Excel formulas & functions. Analytical skills in data manipulation & validation. Excellent written and verbal communication skills.\n",
      "Do they have a minimum of 5 years of IT experience? Do they have experience with Tableau reporting? Experience with Alteryx? Experience with Marketo?\n",
      " Accurately implement methods described in technical documentation developed by our researchers.  Develop accompanying infrastructure to make the models and analytics developed accessible via a variety of access patterns.  Test all software being developed for accuracy and stability.  A bachelors, masters, or PhD in computer science or similar software engineering focused major. A second major, minor, or degree in an adjacent quantitative discipline, such as math, engineering, or physics is a big plus.\n",
      "Initiate technical ideas to improve SiC Crystal growth Develop technical approaches, schedules, and deliverables with detailed project plan  Work closely with other R&D Engineers and implement innovative solutions to SiC crystal growth Develop next-generation SiC growth technology Deliver results with an expedited timeline  Establish, review, and update both short-term and long term experimental plans  Utilize statistical tools to characterize technological processes and determine process reliability and “bottlenecks”. Analyze process/product failure modes. Provide rapid feedback to the SiC production team Readily communicate the ideas, experimental and analytical results to the team in an open and timely manner to accelerate the technology progress Perform fundamental research related to SiC crystal growth Be an expert in analytics tools and data analysis PhD in Materials Science/Physics/Electrical Engineering/Chemical Engineering with Semiconductor knowledge.  7-10 years of experience in the semiconductor industry Knowledge of technical processes used in the fabrication of single crystal substrates such as crystal growth, slicing, and polishing Independent thinking, hands-on experience in a semiconductor environment Analysis skills, including data mining, yield analysis, DOE, and SPC Understanding of crystal growth principles and related physical/chemical phenomena, including thermodynamics of chemical reactions, heat and mass transfer Knowledge of scientific principles and practice of crystal characterization, including electrical, optical and x-ray characterization methods Self Starter attitude Must have excellent communication, documentation and presentation skills Expert in statistical analysis tools Normally 9-5 May require longer working hours in order to complete mission critical tasks Hands-on work Must be able to lift 25 lb. parts\n",
      "Executes standard software solutions, design, development, and technical troubleshooting Writes secure and high-quality code using the syntax of at least one programming language with limited guidance Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems Adds to team culture of diversity, equity, inclusion, and respect Formal training or certification on software engineering concepts and 5+ years applied experience Programming experience in Java, Python, Groovy, Scala, JavaScript, ReactJS Hands on experience with BigData and distributed computation systems (HDFS, Spark, Apache Flink, Databricks) Hands on experience with SQL and NoSQL databases Experience building applications on AWS, Spring Boot and Cloud native foundations Experience across the whole Software Development Life Cycle Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.) Data Modeling skills Experience building AI/ML based applications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Become a part of the core team focused on SEO growth for the company – a company-level objective. Own the metric development for the SEO space, partnering with cross-functional members to ensure clear and actionable insights. Design and run SEO experiments leveraging advanced statistical methodologies, including causal inference. Be the Data science thought leader for the cross-functional working group and provide evidenced-based guidance. Provide actionable insights and recommendations to improve our SEO performance by leveraging your deep expertise in the SEO and Data Science fields. Co-own the strategy, prioritization, and roadmap for SEO growth at the company. Collaborate directly with Marketing, Growth, and Engineering teams. Apply machine learning to identify the most critical web architecture components that drive beneficial SEO growth. Recruit, guide, and mentor junior and mid-level Data Scientists to create a best-in-class Data Science organization. Collaborate with other Data Scientists to continue to enhance the methodologies and practices used across the team that leverage the newest technological developments in the industry. Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable. Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust. Is able to collaborate in person 3 weeks per quarter, traveling if necessary to the hub where the team is based. Holds a PhD or master’s degree in a quantitative field. Has 8+ years of relevant work experience with a proven track record of applying data science methods within the SEO domain. Is fluent in SQL with strong data exploration and manipulation skills. Is proficient in Python, R, or similar programming language. Has an understanding of causal inference methods and their application and ability to apply machine learning techniques when necessary. Has firm knowledge of experiment design and A/B and MVT testing. Is comfortable working with clickstream and web event-related data. Has a self-starting growth mindset and strong communication skills, translating technical insights into impactful business recommendations. Is a creative problem-solver who simplifies problems to their core elements. Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback. A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.  Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits) Disability and life insurance options 401(k) and RRSP matching  Paid parental leave Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days  Home office stipends Caregiver and pet care stipends Wellness stipends Admission discounts Learning and development opportunities\n",
      "8+ Years experience Agile Experience Solid Wealth Management Financial Services experience (Front Office, Middle Office, Back Office Activities) Solid Financial Data understanding (Balances, Positions, Activity) Understanding of how Front End UI, Web Services / APIs, Batch, Databases/Data sources Exposure to program management through standard tools such as JIRA Strong analytical, written and verbal communication skills.  Have strong background in technology (undergrad/bachelor in Computer Science, Information Systems or related Degree). Have good background in Software Development Lifecycle, 3 Tier Application Architecture. A proven ability to build strong collaborative working relationships with business partners and department leads. Display a flexible attitude to work  Basic Understanding of programming languages like C++, Java Understanding of/experience in multi-tier, distributed architecture Good working knowledge of Relational Databases (preferably SQL Server & DB2)  Hands on development experience Exposure to Behavioral Driven Development/Test Driven Development.\n",
      "Designing solutions using AWS services. Building proof of concepts for new tools, services. Working, coordinating with, and guiding offshore team. Overall experience 8-12 years 3+ years of Healthcare Payer experience within last 4 years. (Must) ETL experience. Experience with building Data Ingestion, Pipelines for high volume data. In depth experience with AWS services like Redshift, Glue, Athena, Pyspark, EMR, S3 Python experience. Advanced SQL experience. Familiarity with Dev Ops.\n",
      "Maintain current knowledge of the technology industry, including leading tools and best practices.  Coordinate any 3rd party development and support vendors, perform functional review of 3rd party development work, and elicit user feedback throughout the development life cycle.  Create and maintain technical documentation.  Provide regular status updates regarding status, issues, or risks.  Respond to service requests and service desk ticket escalations.  Review and validate operational policies and ensure they are being met.  Develop and maintain productive relationships with business users, IT members, and management.  At least 10 years of hands-on experience with full life cycle data warehouse technical design (star schemas, cubes, datamarts) and development including ETL, logical and physical data modeling, data mapping from various data sources, loading data warehouse objects including dimensions, hierarchies, fact tables and aggregates, metadata definitions, and report development.  At least 5 years of hands-on experience in architecture design and implementation of business intelligence and predictive analytics on cloud-based Data Warehouses.  At least 5 years of experience with application development, database management and operations including in depth experience with DB object design (Tables/Partitioning/Indexing) and writing highly efficient SQL queries, stored procedures, triggers, functions, and packages.  At least 5 years of experience working closely with business areas to identify business and analytics needs.  At least 5 years of experience translating business requirements into data requests, reports, and dashboards.  At least 5+ years of ERP functional experience particularly with finance and sales modules.  At least 3+ years of using DevOps tool chains and processes.  Proven ability to work independently in converting business and functional requirements into complex reports, data visualizations and dashboards.  Experience with user experience design such as layout, content placement, aesthetics, navigation planning, and usability.  Experience working with Agile methodologies.  Strong communication, collaboration, and diplomatic skills to deliver exceptional service and guide, influence and convince others to adopt change.  Strong written and verbal communication skills for both internal technical members and external business stakeholders with the ability to communicate ideas in both technical and user-friendly terms.  Strong listening and interpersonal skills with a keen attention to detail.  Strong customer service orientation who advocates for providing outstanding customer service.  Ability to forge strong working partnerships within Information Technology and business partners.  Ability to clearly articulate the vision and details for solving business and technical problems that meet or exceed user needs and expectations.  Ability to work effectively within a collaborative team and as an individual contributor, assumes responsibility for project deliverables, works effectively within deadlines and provides overall status of solution readiness.  Highly self-motivated and adept at handling multiple assignments in a timely manner.  Excellent organizational, analytical, time management, prioritization, and task follow-up skills.  BS in a related field, and/or extensive work experience.  Attendance at Kyocera’s headquarters office in Fairfield, NJ per current work policies is required.  Company paid relocation is not provided to the Fairfield, NJ office. The candidate must self-relocate.  MS in Computer Science or in a related field.  Experience with Microsoft PowerBI, SQL Server (SSIS, SSRS, SSAS, BI Server), Azure Data Factory, and Oracle EBS, EBS Accelerator, Oracle Database, Oracle BI, SAP, SAP HANA, SAP BW. Tableau.  Knowledge of financial and accounting concepts  Knowledge of sales reporting and planning  Demonstrated project management skills.  BI and Data warehousing Certifications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has worked with modeling, research design experience, and exposure to cutting-edge algorithms. Experience with methods for causal inference using longitudinal data  Well versed in SQL and Python. Machine Learning Pipeline orchestration with AWS (SageMaker, Batch, Lambda, Step Functions). Experience with Docker Container Platform. Experience with machine learning methods for Bayesian estimation and inference. Experience with Agile Software Development. MS in one of the following disciplines: Computer Science, Statistics, Data Science, Economics, Applied Math, Operational Research, or a related quantitative field + 3 yrs relevant experience; or, PhD +1 yr relevant experience.\n",
      "Engage in the classroom and reply to emails, students’ questions, and discussion boards. Be a faculty leader in your classes. Evaluate and grade students' class work, assignments, and papers within the timeframe set forth by Berkeley policy providing effective feedback to guide student learning and success. Comply with Berkeley guidelines and expectations for quality faculty engagement online. Attend discipline-specific and administrative meetings as scheduled. Support Berkeley College initiatives and departments.  Proficiency in R, Python, Relational and non-relational databases, and Cloud computing with in-depth knowledge of machine learning and artificial intelligence libraries, and APIs. Demonstrated success in teaching at an institution of higher education. A willingness to travel and teach at multiple campuses across NJ, if applicable. An ability to teach classes during the day, the evening, and/or the weekend. Experience using technology and interactive electronic materials to support teaching and learning. Experience using a Learning Management System such as Canvas.\n",
      " Lead initiatives to improve quality received from assigned suppliers  Support the qualification of parts and/or introduction of new suppliers  Manage supplier’s corrective action implementation through the Supplier Corrective Action process  Evaluate and disposition rejected material, as required  Use statistical analysis and risk management techniques to analyze quality data to identify trends and implement actions as needed  Provide guidance for process changes, including guidance on requirements for supplier and part’s qualification  Ability to travel to suppliers locations to address quality concerns  Lead/Participate on CAPA investigations, as required  Bachelor’s degree in Science or Engineering field of study  5-8 years of successful experience in medical device and quality engineering, and successful demonstration of responsibilities and knowledge as listed above  Incoming Inspection experience, preferred  Certified Quality Engineer (CQE), preferred  Certified Quality Auditor (CQA)/Lead Auditor Certification, preferred  Six Sigma Certification, preferred  Deep professional know-how and experience. Transfers and applies know-how to / in various contexts. Solid professional judgment and problem solving competence. Improves existing processes and approaches.\n",
      "\n",
      "Work with project teams to manage data using Earthsoft EQuIS Professional As an Environmental Data Specialist, support the use of data solutions at GEI Consultants As a project consultant, work on client projects providing data management services including coordinating field activities, serving as liaison to the analytical labs, and coordinating with 3rd party validators Design EDDs for specialized field events Perform historical data migrations for analytical, gauging, sampling, stratigraphy, etc. Track submission of field/lab EDDs, load EDDs, and run required reports via EQuIS Professional Provide QA/QC for project teammates as it applies to data accuracy and completeness Maintain and update reference values including Action Levels Manage budgets and timelines for internally facing and externally facing projects Support Data Scientists, Engineers, Geologists, Staff Scientists, and other stakeholders at GEI by discovering opportunities to create efficiencies with data that solve a variety of client-driven business needs Stay current on the latest features in software for environmental data management by attending vendor webinars, self-paced training, and testing in our development environment Support internal and external business development with demonstrations and trainings Oversee and deploy field data collection software (including EDGE). Maintain and distribute reference values and data capture requirements to ensure complete field EDDs Occasional travel to offices or client sites Bachelor’s Degree, or equivalent experience, from an accredited college or university required A minimum of 3 years of experience in a consultancy providing data management services Proven proficiency with Earthsoft desktop software Understanding of environmental field and analytical lab procedures/nomenclature In-depth knowledge of the Earthsoft schema (professional, edge, reports) and understanding of table types and relationships Experience with Microsoft SQL Server to design/maintain views and stored procedures Ability to work with XML Earthsoft format files Knowledge of installing and upgrading Earthsoft on-premises applications Experience with EDGE Experience with VB.net for maintaining Earthsoft custom reports (DLLs) Experience with gINT Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus Pay Range For This Position: $37.00-45.00/hour Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More Well-Being Program and Paid Parental Leave Commuter Benefits Hybrid Work Schedules and Home Office and Cell Phone Stipends GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses Paid Holidays and Generous Paid Time Off Program Rewards and Recognition GEI-Funded Profit Sharing and 401(k) Opportunity to be an Owner and Shareholder (Learn more here) A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion And More…\n",
      "\n",
      " Highly proficient in Microsoft Office Suite (Word, Excel, and PowerPoint)  Experience in using some advanced analytical tools (SQL /R /Python) is preferred  Passionate about using data to inform decision making and possess the curiosity to research and solve complex problems involving data and business analytics  A quick learner who is willing to learn and work in a team in a fast-paced environment  Legally authorized to work in the United States of America\n",
      " This role is involved in conducting Lab studies.  The studies involve blood. Should be comfortable working with blood.  Should be able to independently execute studies.  Need to have great lab skills, experience with data analysis, write reports & study protocols.  Need to have wet lab skills such as pipetting and experience with in vitro studies.  Day to day involves designing studies and attending team meetings, writing protocols, executing testing in the lab, doing data analysis and providing final reports.  Generally, data analysis is done in Excel or Minitab, GraphPad.  Experience doing data analysis in Excel or Minitab or GraphPad is a big plus.  B.S./M.S. with minimum 2 years industry experience or a fresh Ph.D. (contingent on the Ph.D. being lab based). PhD should be from a related wet lab.  Degree in Biomedical engineering or Biology is preferred. But if the candidate has a related degree but has worked in a biology lab with wet lab experience, they would be considered as well.  Phone interview with HM followed by a panel interview.\n",
      "Data Warehouse Migration: Support the migration of HR data from legacy systems to new data warehouses, ensuring data integrity and accuracy throughout the process. Data Validation and Cleaning: Conduct thorough data validation and cleaning to ensure the quality and reliability of HR data. Collaboration with IT Department: Work closely with the IT department and other stakeholders to ensure seamless integration and alignment of HR data systems with organizational technology infrastructure. Documentation: Develop comprehensive documentation on data migration processes, data validation protocols, and user manuals for HR data systems. Process Improvement: Identify opportunities for improving data management practices and contribute to the development of more efficient and effective HR analytics processes. Education: Currently enrolled in a Bachelor’s or Master’s degree program in Business Studies, Data Science, Information Technology, or a related field. For individuals seeking to return to the field or switch job domains: a Bachelor's degree or certificate in Business Studies, Data Science, Information Technology, or a related field, coupled with a demonstrated passion for data analytics and a willingness to refresh their skills, is required. SQL Knowledge: Strong understanding of SQL for querying databases, data manipulation, and analysis. Analytical Skills: Excellent analytical and problem-solving skills with a keen attention to detail. Independence: Ability to work independently with minimal supervision, demonstrating initiative and self-motivation. Communication Skills: Strong verbal and written communication skills, with the ability to clearly document processes and present data findings. Collaboration: Proven ability to collaborate effectively with cross-functional teams, including IT and HR departments. Data Visualization Tools: Familiarity with Tableau or similar data visualization tools is a plus. Experience: Previous internship or project experience in data analysis, HR analytics, or a related field is highly desirable. Market competitive salary with an anticipated base compensation range of $18.46 - $53.81 USD. Actual salaries will vary depending on a candidate's experience, qualifications, skills, and location. Medical, Dental, and Vision Insurance.  Telehealth coverage Flexible work schedules and work from home opportunities Development and career growth opportunities Open Time Off in addition to 10 paid holidays 401(k) matching program Adoption Assistance Fertility treatments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Executes standard software solutions, design, development, and technical troubleshooting  Writes secure and high-quality code using the syntax of at least one programming language with limited guidance  Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications  Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation  Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity  Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development  Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems  Adds to team culture of diversity, equity, inclusion, and respect  Formal training or certification on software engineering concepts and 5+ years applied experience   Programming experience in Java, Python, Groovy, Scala, JavaScript, ReactJS   Hands on experience with BigData and distributed computation systems (HDFS, Spark, Apache Flink, Databricks)   Hands on experience with SQL and NoSQL databases   Experience building applications on AWS, Spring Boot and Cloud native foundations   Experience across the whole Software Development Life Cycle   Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security   Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)   Data Modeling skills   Experience building AI/Client based applications\n",
      "PhD in a scientific or engineering discipline (or equivalent experience). Track record of high achievement in scientific research. Strong analytical and mathematical abilities. Comfort with large data and programming. No knowledge of finance is required. Competitive salary, bonus, and incentive compensation based on overall company performance. Fantastic resources, accumulated over decades, for turning ideas into reality. Comprehensive, first-class benefits (including excellent medical and dental insurance, 401(k), HRA, FSA, life insurance, daily catered lunch, and an onsite gym). For qualified employees, the opportunity to invest in our funds.\n",
      " Design, develop, and implement scalable data pipelines and ETL processes using Java, Python, and Spark.  Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and design efficient solutions.  Manage and optimize Spark clusters to ensure high performance and reliability.  Perform data exploration, data cleaning, and data transformation tasks to prepare data for analysis and modeling.  Develop and maintain data models and schemas to support data integration and analysis.  Implement data quality and validation checks to ensure accuracy and consistency of data.  Utilize REST API development skills to create and integrate data services and endpoints for seamless data access and consumption.  Monitor and troubleshoot data pipeline performance, identifying and resolving bottlenecks and issues.  Stay updated with the latest technologies and trends in big data, data engineering, data science, and REST API development, and provide recommendations for process improvements.  Mentor and guide junior team members, providing technical leadership and sharing best practices.  Master's degree in Computer Science, Data Science, or a related field.  Minimum of 3 years of professional experience in data engineering, working with Java, Python, Spark, and big data technologies.  Strong programming skills in Java and Python, with expertise in building scalable and maintainable code.  Proven experience in Spark cluster management, optimization, and performance tuning.  Solid understanding of data science concepts and experience working with data scientists and analysts.  Proficiency in SQL and experience with relational databases (e.g., Snowflake, Delta Tables).  Experience in designing and developing REST APIs using frameworks such as Flask or Spring.  Familiarity with cloud-based data platforms (e.g.Azure)  Experience with data warehousing concepts and tools (e.g., Snowflake, BigQuery) is a plus.  Strong problem-solving and analytical skills, with the ability to tackle complex data engineering challenges.  Excellent communication and collaboration skills, with the ability to work effectively in a team-oriented environment.\n",
      "Executes standard software solutions, design, development, and technical troubleshooting Writes secure and high-quality code using the syntax of at least one programming language with limited guidance Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems Adds to team culture of diversity, equity, inclusion, and respect Formal training or certification on software engineering concepts and 5+ years applied experience Programming experience in Java, Python, Groovy, Scala, JavaScript, ReactJS Hands on experience with BigData and distributed computation systems (HDFS, Spark, Apache Flink, Databricks) Hands on experience with SQL and NoSQL databases Experience building applications on AWS, Spring Boot and Cloud native foundations Experience across the whole Software Development Life Cycle Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.) Data Modeling skills Experience building AI/ML based applications\n",
      "This role is involved in conducting Lab studies. The studies involve blood. Should be comfortable working with blood. Should be able to independently execute studies. Need to have great lab skills, experience with data analysis, write reports & study protocols. Need to have wet lab skills such as pipetting and experience with in vitro studies. Day to day involves designing studies and attending team meetings, writing protocols, executing testing in the lab, doing data analysis and providing final reports. Generally, data analysis is done in Excel or Minitab, GraphPad. Experience doing data analysis in Excel or Minitab or GraphPad is a big plus. B.S./M.S. with minimum 2 years industry experience or a fresh Ph.D. (contingent on the Ph.D. being lab based). PhD should be from a related wet lab. Degree in Biomedical engineering or Biology is preferred. But if the candidate has a related degree but has worked in a biology lab with wet lab experience, they would be considered as well.\n",
      "Find automation opportunities gathering business knowledge from stakeholders, exploring large volumes of complex data, and testing hypothesis using traditional and cutting-edge machine learning models. Partner with different parts of the business, understanding key challenges and metrics of success, communicating results, and gathering feedback to improve model performance and expectations. Build machine learning models and deploy these models following all relevant processes and governance. BS degree in Computer Science, Mathematics, Engineering, or related field. Solid programming skills with Python, R, or other equivalent languages, and experience using frameworks as Scikit-Learn. Strong mathematical and statistical skills, including knowledge of exploratory data analysis, statistical models, GLM, decision trees, clustering, bootstrapping.  Ability to identify model and data issues, then propose, prototype, and evaluate alternatives, prioritizing the business benefits rather than the trendiness of the solution.  Curiosity exploring large and complex datasets, extracting big picture insights as well as identifying critical low-level details.  Great communication and presentation skills that enable collaboration and transparency with non-technical senior leaders as well as technical counterparts. Self-motivation and comfortable working with a geographically distributed team. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Work on programming duties related to deep learning and computer vision.   Running simulation experiments.   Bachelor in Science in Computer Science  At the university's discretion, the education and experience prerequisites may be exempted where the candidate can demonstrate to the satisfaction of the university, an equivalent combination of education and experience specifically preparing the candidate for success in the position\n",
      " A mindset built on simplicity reuse  Proficiency to work with Senior Business stakeholders and translate business needs into technical requirements  Leadership skills to manage ad-hoc analysis or design deep dives  Understanding of the development lifecycle to ensure the designs are practical adopted by the delivery teams  10+ years’ experience with at least 3+ years’ experience as a BA/FA  Delivery focused techno-functional role  Programming experience with Python or Java/.Net  Excellent analytical and problem solving skills  Deep understanding of Capital Markets with focus on Credit Risk, Market Risk or Capital calculations  Understanding of regulations within the Capital Markets space (Basel, CRR, CRD IV etc)  Attention to detail and self-starter, with an ability to identify risks and issues and suggest improvements.  Excellent communication, negotiation, networking and influencing skills  Ability to work across multiple business groups and domains  Ability to work in a fast paced environment and work under pressure  Collaborative, with an ability to share information, transfer knowledge and train new team members  Proven ability to balance business demands of different stakeholders and IT fulfilment in terms of standardization, reducing risk and increasing IT flexibility  Experience building high-performance, enterprise applications at scale  Financial and regulatory reporting experience; specifically build a reporting solution that facilitates the creation, publication and distribution of reports both on a regular basis and ad-hoc.  Experience of having worked on a Greenfield project, ideally within a large financial institution or a financial product development company. He or she may be required to demonstrate this during the interview process.  Additionally, the candidate must have solid experience of change management and delivery frameworks such as SDLC, test driven development (TDD) and should have functional delivery of more than one large scale IT project.  Knowledge of Big Data Architectures and Cloud computing  Experience with Hadoop/Hive, Neo4J, Apache Spark, Kafka and MongoDB is a plus  Experience with data visualization tools like Tableau, Kibana, etc.  Knowledge of machine-learning techniques, classifiers and statistical methods  Exceptional intelligence and problem-solving skills  Excellent communication skills  BS/MS in Computer Science, Engineering, or any quantitative discipline\n",
      "Camera System Selection & Integration: Collaborate with the System Integration Engineer to select and implement the optimal camera systems for our robotic cell, ensuring high-quality production monitoring. Model Development: Create and refine machine vision models that enhance our ability to assess and ensure product quality through advanced imaging techniques. Code Development: Write robust, efficient code to power our machine vision systems, continuously improving their accuracy and reliability. Vision AI System Advancement: Innovate and develop new vision AI systems to enhance the capabilities of our robotic cell, focusing on improving overall reliability and performance. Collaborative Innovation: Work closely with a cross-disciplinary team to identify opportunities for system enhancements, contributing to the ongoing evolution of our technology. Educational Background: Bachelor’s degree in Computer Science, Electrical Engineering, Robotics, or a related field. Relevant Experience: 1-2 years of experience in machine vision, image processing, or a related field. Experience in a startup environment is highly desirable. Technical Proficiency: Strong skills in machine vision technologies, including experience with camera selection, image processing algorithms, and machine learning models. Coding Skills: Proficiency in programming languages relevant to machine vision and AI, such as Python, C++, or MATLAB. Startup Mindset: A hungry, entrepreneurial spirit, with a willingness to wear multiple hats and a drive to thrive in a fast-paced startup environment. Problem-Solving Ability: Excellent analytical skills and the ability to tackle complex problems with innovative solutions. Communication Skills: Strong communication abilities to effectively collaborate with team members and contribute to interdisciplinary projects. Continuous Learning: A commitment to continuous learning and staying abreast of the latest advancements in machine vision and AI technologies. Interest in Robotics: A passion for robotics and automation, demonstrated through academic projects, internships, or personal pursuits. Honesty & Authenticity: Build great technology and don’t lie Positive Impact: Create something lasting and valuable together Rewarded Performance: Value accomplishments along the journey Trust & Reliability: Confident in our skills and rely on each other Transparency & Frankness: Communicate openly what’s going on\n",
      "\n",
      "Master's degree in Computer Science, Information Systems or MBA with 12 - 15+ yrs. of experience or a Bachelor’s degree with a minimum of 20 yrs. Experience Proven track record of at least 10 years in MDM leadership roles within a global organization, preferably in the CPG industry. Strong understanding of material/product and customer data management processes. Experience with MDM tools and technologies. Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams. Strong analytical and problem-solving abilities. Leadership qualities, including the ability to inspire and motivate teams. Lead large Ongoing MDM Service teams globally across 4 regions (NA, Europe, APAC and LatAm) for CPG Business Segments Build, lead, and mentor a high-performing MDM team, providing guidance and fostering a culture of excellence. Define the vision for MDM Service operations and drive continuous improvement initiatives. Provide direction to drive operational excellence for creation and maintenance of master data for Product and Customer domains through timeliness, accuracy, right-first-time and quality-of-service KPIs Establish MDM Service Governance to engage and collaborate with global/regional Segment functional stakeholders to gain continuous support for ongoing data improvements as well as identify business priorities to support. Set clear performance expectations, conduct regular performance evaluations, and identify opportunities for professional growth. Implement and enforce data governance policies, standards, and best practices to ensure data quality, security, and compliance in partnership with Data Councils. Create and maintain data stewardship programmes to involve business users in data quality initiatives. Develop and lead culture of value creation powered by master data through continuous improvements, automation, and standardization to improve the overall quality of service. Drive cultural change within the organization to promote data-centric decision-making and data-driven processes. Lead change management efforts to ensure the successful adoption of MDM practices across departments. Define key performance indicators (KPIs) and metrics to measure the effectiveness and impact of MDM initiatives. Regularly report on MDM program performance to senior leadership. Work with over 130,000 diverse and talented Associates, all guided by the Five Principles. Join a purpose driven company, where we’re striving to build the world we want tomorrow, today. Best-in-class learning and development support from day one, including access to our in-house Mars University. An industry competitive salary and benefits package, including company bonus.\n",
      "3+ years experience working with an analytics team as a SQL expert Experience working with Azure highly preferred Proven experience in a role requiring strong attention to detail and communication skills. Ability to effectively engage with stakeholders at all levels of the organization. Remote with 1x quarterly travel onsite Base: 110-130k base USC/GC Holders at this time cannot onboard OPT or H1B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute fan-focused research initiatives, including planning, administering, and analyzing year-round consumer surveys.  Gather, validate, and synthesize fan data from multiple sources.  Leverage qualitative research to augment customer profiles. Build and maintain internal reports and dashboards to equip business unit leaders with actionable fan insights.  Continuously improve fan research-related tools and capabilities. Complete day-to-day research requests. Other duties as assigned.  Proactive and resourceful self-starter who can work independently within set objectives and consistently meet deadlines.  Excellent written and visual communication skills with very strong attention to detail. Ability to maintain confidential and/or proprietary information. 2-3 years of professional experience in consumer insights, market research, and/or analytics. Intermediate to advanced knowledge of Microsoft Excel and PowerPoint required; 1+ year of demonstrable experience with PowerBI or other data visualization tool preferred. Prior professional team, major brand, or agency experience is strongly preferred. Medical/Dental/Vision/Flexible Spending Accounts (all LGBT friendly) Pretax Transportation Benefit Generous parental leave policies 401K (100% up to 5% is matched, after 1 year of service) Unlimited Paid Time Off 13 Paid Holidays ½ Day Summer Fridays Complimentary or Discounted Sports & Concert Tickets On-Site Fitness Rooms Other League & Partner Discounts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for url in urls:\n",
    "#     page = requests.get(url)\n",
    "#     time.sleep(2)\n",
    "#     soup = BeautifulSoup(page.text, 'lxml')\n",
    "#     os.chdir(SCRAPED_JOBS_PATH)\n",
    "    \n",
    "#     for div in soup.find_all('div', class_='top-card-layout__entity-info'):\n",
    "        \n",
    "#         position_title = div.h1.text\n",
    "#         company = (div.h4.div.span.a.text).lstrip().rstrip()\n",
    "        \n",
    "#         file_name = f\"{position_title.lower().replace(' ', '_')}-{company.lower().replace(' ', '')}.txt\"\n",
    "#         file_name = file_name.replace('(', \"_\") if file_name.__contains__(\"(\") else file_name\n",
    "#         file_name = file_name.replace(')', \"_\") if file_name.__contains__(\")\") else file_name\n",
    "#         file_name_exists = os.path.exists(SCRAPED_JOBS_PATH + \"/\" + file_name)\n",
    "        \n",
    "#         if file_name_exists:\n",
    "#             pass\n",
    "#         else:\n",
    "#             try:\n",
    "#                 with open(file_name, \"w\", encoding=\"utf-8\") as my_file:\n",
    "\n",
    "#                     my_file.write(\"Position title: \" + position_title)\n",
    "#                     my_file.write(\"\\n\")\n",
    "#                     my_file.write(\"\\n\")\n",
    "\n",
    "#                     my_file.write(\"Company: \" + company)\n",
    "#                     my_file.write(\"\\n\")\n",
    "#                     my_file.write(\"\\n\")\n",
    "\n",
    "            # section = soup.find_all('section', class_='show-more-less-html')\n",
    "\n",
    "            # section_divs = [i for i in section]\n",
    "            # job_desc_sentences = [i.text for i in section_divs[0].find_all('li')]\n",
    "            # job_desc_sentences = ' '.join(job_desc_sentences)\n",
    "            # print(job_desc_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecd99c",
   "metadata": {},
   "source": [
    "## Loop through ```urls``` list to create a job description file for each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc8d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    page = requests.get(url)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "    os.chdir(SCRAPED_JOBS_PATH)\n",
    "    \n",
    "    for div in soup.find_all('div', class_='top-card-layout__entity-info'):\n",
    "        \n",
    "        position_title = div.h1.text\n",
    "        company = (div.h4.div.span.a.text).lstrip().rstrip()\n",
    "        \n",
    "        file_name = f\"{position_title.lower().replace(' ', '_')}-{company.lower().replace(' ', '')}.txt\"\n",
    "        file_name = file_name.replace('(', \"_\") if file_name.__contains__(\"(\") else file_name\n",
    "        file_name = file_name.replace(')', \"_\") if file_name.__contains__(\")\") else file_name\n",
    "        file_name_exists = os.path.exists(SCRAPED_JOBS_PATH + \"/\" + file_name)\n",
    "        \n",
    "        if file_name_exists:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                with open(file_name, \"w\", encoding=\"utf-8\") as my_file:\n",
    "\n",
    "#                     my_file.write(\"Position title: \" + position_title)\n",
    "#                     my_file.write(\"\\n\")\n",
    "#                     my_file.write(\"\\n\")\n",
    "\n",
    "#                     my_file.write(\"Company: \" + company)\n",
    "#                     my_file.write(\"\\n\")\n",
    "#                     my_file.write(\"\\n\")\n",
    "\n",
    "                    section = soup.find_all('section', class_='show-more-less-html')\n",
    "                    \n",
    "                    section_divs = [i for i in section]\n",
    "                    job_desc_sentences = [i.text for i in section_divs[0].find_all('li')]\n",
    "                    job_desc_sentences = ' '.join(job_desc_sentences)\n",
    "                        \n",
    "\n",
    "                    try:\n",
    "                        my_file.write(job_desc_sentences)\n",
    "                        my_file.write(\"\\n\")\n",
    "\n",
    "                    except FileNotFoundError:\n",
    "                        pass\n",
    "                        \n",
    "#                     my_file.write(\"Job URL: \" + url)\n",
    "                    \n",
    "            except (FileNotFoundError, OSError) as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9929791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00326678",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b9bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.wsj.com/market-data/quotes/US/XNAS/AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7194ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
